{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the JupyterHub Deployment Docs for ENGR114 2019Q4 This documentation serves as a record of the JupyterHub Deployment for ENGR114 Fall 2019 at Portland Commmunity College. The GitHub repo for the deployment can be found here: https://github.com/ProfessorKazarinoff/jupyterhub-ENGR114-2019Q4 Click the menu items on the left to view the deployment steps. Or start Here and click the arrows at the bottom of each page. What is JupyterHub? JupyterHub is a cloud server-hosted distributed Jupyter notebook deployment. JupyterHub allows users to log into a server and write Python code within a web browswer without installing any software on their local machine. After JupyterHub is deployed, anywhere you have an internet connection, you can bring up a Jupyter notebook in your browser and write/run Python code. The Jupyter notebook interface that JupyterHub provides is the same Jupyter notebook interface you can run locally. Because JupyterHub runs in a web browser, it even works on tablets and phones. Why JupyterHub? Why Jupyter Hub ? I am teaching an engineering programming course Fall of 2019. In previous quarters, I've taught MATLAB for the programming class. But this fall, I am teaching Python and cover the same concepts and learning outcomes. When we use Python in the class this Fall, I would like to spend the class time coding and solving problems. I don't want to spend time during class downloading Python, creating virtual environments, troubleshooting installs, dealing with system vs. non-system versions of Python, installing packages, dealing with folder structure, explaining the difference between conda and pip, teaching command-line arguments, going over Python on Windows compared to Python on MacOS... The solution is to use JupyterHub. A series of blog posts documents my first JupyterHub deployment in Summer 2018. This documentation builds upon that previous experience. A deployment of JupyterHub Winter 2019 documents by second JupyterHub installation. This documentation closely follows the same steps with only a few minor alterations. Main Steps Install PuTTY, generate SSH keys Create a new Ubuntu 18.04 server on Digital Ocean Install JupyterHub and Python packages Aquire and link domain name to server Aquire SSL cirt Create Cookie Secret, Proxy Auth Token, and dhparam.pem Install and configure Nginx Configure JupyterHub Google Authentication Create a custom login page Cull idle servers script","title":"Home"},{"location":"#welcome-to-the-jupyterhub-deployment-docs-for-engr114-2019q4","text":"This documentation serves as a record of the JupyterHub Deployment for ENGR114 Fall 2019 at Portland Commmunity College. The GitHub repo for the deployment can be found here: https://github.com/ProfessorKazarinoff/jupyterhub-ENGR114-2019Q4 Click the menu items on the left to view the deployment steps. Or start Here and click the arrows at the bottom of each page.","title":"Welcome to the JupyterHub Deployment Docs for ENGR114 2019Q4"},{"location":"#what-is-jupyterhub","text":"JupyterHub is a cloud server-hosted distributed Jupyter notebook deployment. JupyterHub allows users to log into a server and write Python code within a web browswer without installing any software on their local machine. After JupyterHub is deployed, anywhere you have an internet connection, you can bring up a Jupyter notebook in your browser and write/run Python code. The Jupyter notebook interface that JupyterHub provides is the same Jupyter notebook interface you can run locally. Because JupyterHub runs in a web browser, it even works on tablets and phones.","title":"What is JupyterHub?"},{"location":"#why-jupyterhub","text":"Why Jupyter Hub ? I am teaching an engineering programming course Fall of 2019. In previous quarters, I've taught MATLAB for the programming class. But this fall, I am teaching Python and cover the same concepts and learning outcomes. When we use Python in the class this Fall, I would like to spend the class time coding and solving problems. I don't want to spend time during class downloading Python, creating virtual environments, troubleshooting installs, dealing with system vs. non-system versions of Python, installing packages, dealing with folder structure, explaining the difference between conda and pip, teaching command-line arguments, going over Python on Windows compared to Python on MacOS... The solution is to use JupyterHub. A series of blog posts documents my first JupyterHub deployment in Summer 2018. This documentation builds upon that previous experience. A deployment of JupyterHub Winter 2019 documents by second JupyterHub installation. This documentation closely follows the same steps with only a few minor alterations.","title":"Why JupyterHub?"},{"location":"#main-steps","text":"Install PuTTY, generate SSH keys Create a new Ubuntu 18.04 server on Digital Ocean Install JupyterHub and Python packages Aquire and link domain name to server Aquire SSL cirt Create Cookie Secret, Proxy Auth Token, and dhparam.pem Install and configure Nginx Configure JupyterHub Google Authentication Create a custom login page Cull idle servers script","title":"Main Steps"},{"location":"DNS/","text":"DNS Routing After we verify JupyterHub is working with all the default settings, we need to link a domain name our Digital Ocean server. That way students can visit a domain like engr114.org instead of having to visit an IP address like 215.154.998.607. DNS Routing Link domain name to server IP address Google Domains Digital Ocean DNS Next Steps Link domain name to server IP address When we started JupyterHub in the previous step, it ran, we could log in, and we could run Python code. What's not to like, right? Well, security is the big problem. Warning Do not run JupyterHub in production without SSL security. In the initial setup, JupyterHub was running under regular http, not https. With a web application that has usernames and passwords, like JupyterHub, having https and SSL security is best (or really manditory). In order to use https, we need to generate an SSL certificate. The SSL certificate should correspond to the domain name linked to our server. Therefore, the first step on our way to SSL security, is purchasing a domain name and pointing the domain name at the Digital Ocean DNS servers. Then we'll link the domain name to our JupyterHub server. Google Domains I purchased the domain for this JupyterHub deployment from Google Domains . The domain cost $12/year (which seems pretty reasonable) and Google domains makes set up pretty easy. After purchasing the domain, I added the Digital Ocean DNS servers as a set of custom name servers to my domain options on Google Domains. To add a set of custom name servers using the Google Domains dashboard, click the button with the two bars under the DNS header. This brings up a page where you can enter in the Digital Ocean DNS server addressess. The name servers to add are: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Make sure to click the radio button [Use custom name servers] and click [Save]. Digital Ocean DNS Now we are going to set our domain to link to the IP address of our server on Digital Ocean. Log into Digital Ocean and in the upper right select [Create] \u2192 [Domains/DNS] In the [Add a domain] field, type in the domain name without http, but including .com (or .edu/.org/.net) such as mydomain.org , then click [Add Domain]. This brings up a panel where we can add a DNS record. I want the JupyterHub server to have the web address of the domain I purchased, no subdomains like notebooks.mydomain.com for this installation of JupyterHub. I entered @ in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. I also entered www in the text field [Enter @ or hostname], then selected the JupyterHub droplet like before. This way www.mydomain.org will route to our JupyterHub server as well. After completing this step, there will be a couple of new DNS records on the Digital Ocean dashboard. The results will look something like the screen capture below: It takes a couple minutes for the DNS switchover to complete. https://www.whatsmydns.net can be used to check the NS and A records of your domain and see if the domain name is getting through. The first time I set up DNS on Digital Ocean, I added the custom DNS servers to Google Domains but neglected to select the [use custom name servers] radio button on the Google Domains dashboard. It looked like the domain was routing to Digital Ocean, but actually the domain was just staying with Google. Once I clicked the [use custom name servers] radio button and waited a couple minutes, the change over happened. It did take a bit of time though; not hours, but more than a few minutes. Next Steps The next step is to obtain an SSL certificate so we can add SSL security and use https instead of http.","title":"DNS Routing"},{"location":"DNS/#dns-routing","text":"After we verify JupyterHub is working with all the default settings, we need to link a domain name our Digital Ocean server. That way students can visit a domain like engr114.org instead of having to visit an IP address like 215.154.998.607. DNS Routing Link domain name to server IP address Google Domains Digital Ocean DNS Next Steps","title":"DNS Routing"},{"location":"DNS/#link-domain-name-to-server-ip-address","text":"When we started JupyterHub in the previous step, it ran, we could log in, and we could run Python code. What's not to like, right? Well, security is the big problem. Warning Do not run JupyterHub in production without SSL security. In the initial setup, JupyterHub was running under regular http, not https. With a web application that has usernames and passwords, like JupyterHub, having https and SSL security is best (or really manditory). In order to use https, we need to generate an SSL certificate. The SSL certificate should correspond to the domain name linked to our server. Therefore, the first step on our way to SSL security, is purchasing a domain name and pointing the domain name at the Digital Ocean DNS servers. Then we'll link the domain name to our JupyterHub server.","title":"Link domain name to server IP address"},{"location":"DNS/#google-domains","text":"I purchased the domain for this JupyterHub deployment from Google Domains . The domain cost $12/year (which seems pretty reasonable) and Google domains makes set up pretty easy. After purchasing the domain, I added the Digital Ocean DNS servers as a set of custom name servers to my domain options on Google Domains. To add a set of custom name servers using the Google Domains dashboard, click the button with the two bars under the DNS header. This brings up a page where you can enter in the Digital Ocean DNS server addressess. The name servers to add are: ns1.digitalocean.com ns2.digitalocean.com ns3.digitalocean.com Make sure to click the radio button [Use custom name servers] and click [Save].","title":"Google Domains"},{"location":"DNS/#digital-ocean-dns","text":"Now we are going to set our domain to link to the IP address of our server on Digital Ocean. Log into Digital Ocean and in the upper right select [Create] \u2192 [Domains/DNS] In the [Add a domain] field, type in the domain name without http, but including .com (or .edu/.org/.net) such as mydomain.org , then click [Add Domain]. This brings up a panel where we can add a DNS record. I want the JupyterHub server to have the web address of the domain I purchased, no subdomains like notebooks.mydomain.com for this installation of JupyterHub. I entered @ in the text field labeled [Enter @ or hostname]. Then selected the Droplet (our JupyterHub server) that the web address will route to. I also entered www in the text field [Enter @ or hostname], then selected the JupyterHub droplet like before. This way www.mydomain.org will route to our JupyterHub server as well. After completing this step, there will be a couple of new DNS records on the Digital Ocean dashboard. The results will look something like the screen capture below: It takes a couple minutes for the DNS switchover to complete. https://www.whatsmydns.net can be used to check the NS and A records of your domain and see if the domain name is getting through. The first time I set up DNS on Digital Ocean, I added the custom DNS servers to Google Domains but neglected to select the [use custom name servers] radio button on the Google Domains dashboard. It looked like the domain was routing to Digital Ocean, but actually the domain was just staying with Google. Once I clicked the [use custom name servers] radio button and waited a couple minutes, the change over happened. It did take a bit of time though; not hours, but more than a few minutes.","title":"Digital Ocean DNS"},{"location":"DNS/#next-steps","text":"The next step is to obtain an SSL certificate so we can add SSL security and use https instead of http.","title":"Next Steps"},{"location":"building_docs/","text":"Building Docs The documentation for this JupyterHub deployment was completed using mkdocs , the mkdocs-material theme and deployed on GitHub pages. The directory structure of the GitHub repo that houses the deployment files and docs looks like this: . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 theme \u251c\u2500\u2500 etc \u2502 \u251c\u2500\u2500 jupyterhub \u2502 \u251c\u2500\u2500 nginx \u2502 \u2514\u2500\u2500 systemd \u2514\u2500\u2500 opt \u2514\u2500\u2500 miniconda3 Inside the docs/ directory is another docs/ subdirectory with all of markdown files that make up the documentation. There is also a mkdocs yaml file in the docs/ directory. When calling mkdocs commands from the command line, you need to be in the folder with the mkdocs.yml file. ./docs/ \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 images/ \u2502 \u251c\u2500\u2500 add_users.md \u2502 \u251c\u2500\u2500 assignments_on_github.md \u2502 \u251c\u2500\u2500 building_docs.md \u2502 \u251c\u2500\u2500 cookie_secret_proxy_auth_token.md \u2502 \u251c\u2500\u2500 custom_login_page.md \u2502 \u251c\u2500\u2500 dns_routing.md \u2502 \u251c\u2500\u2500 extra_configuration.md \u2502 \u251c\u2500\u2500 google_oauth.md \u2502 \u251c\u2500\u2500 index.md \u2502 \u251c\u2500\u2500 install_jupyterhub.md \u2502 \u251c\u2500\u2500 jupyterhub_config.md \u2502 \u251c\u2500\u2500 nbgitpuller_defaut_url.md \u2502 \u251c\u2500\u2500 nbgitpuller_plugin.md \u2502 \u251c\u2500\u2500 nginx_config.md \u2502 \u251c\u2500\u2500 nginx_install.md \u2502 \u251c\u2500\u2500 periodic_maintenance.md \u2502 \u251c\u2500\u2500 server_setup.md \u2502 \u251c\u2500\u2500 setup_and_tools.md \u2502 \u251c\u2500\u2500 slides \u2502 \u251c\u2500\u2500 ssh_keys.md \u2502 \u251c\u2500\u2500 ssl_cirtificates.md \u2502 \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 systemd.md \u2502 \u251c\u2500\u2500 useful_commands.md \u2502 \u2514\u2500\u2500 what_is_jupyterhub.md \u2514\u2500\u2500 theme \u251c\u2500\u2500 assets \u2514\u2500\u2500 partials To build the docs locally, make sure you have Python installed (I use Anaconda ). Start out by cloning the repo: git clone https://github.com/ProfessorKazarinoff/jupyterhub-engr101.git cd into the cloned repo, and create a virtual environment. Install the Python packages needed to build the docs. cd jupyterhub-engr101.git conda create -n jupyterhub-docs python=3.7 conda activate jupyterhub-docs (jupyterhub-docs) pip install -r requirements-docs.txt cd into the docs dir, and run mkdocs build and mkdocs serve cd docs ls # mkdocs.yml mkdocs build mkdocs serve Look at the built site on local host: http://localhost:8000/ Deploy to GitHub pages mkdocs gh-deploy If the deployment returns an error, try the following command instead: mkdocs gh-deploy --force","title":"Building the Docs"},{"location":"building_docs/#building-docs","text":"The documentation for this JupyterHub deployment was completed using mkdocs , the mkdocs-material theme and deployed on GitHub pages. The directory structure of the GitHub repo that houses the deployment files and docs looks like this: . \u251c\u2500\u2500 LICENSE \u251c\u2500\u2500 README.md \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 mkdocs.yml \u2502 \u2514\u2500\u2500 theme \u251c\u2500\u2500 etc \u2502 \u251c\u2500\u2500 jupyterhub \u2502 \u251c\u2500\u2500 nginx \u2502 \u2514\u2500\u2500 systemd \u2514\u2500\u2500 opt \u2514\u2500\u2500 miniconda3 Inside the docs/ directory is another docs/ subdirectory with all of markdown files that make up the documentation. There is also a mkdocs yaml file in the docs/ directory. When calling mkdocs commands from the command line, you need to be in the folder with the mkdocs.yml file. ./docs/ \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 docs/ \u2502 \u251c\u2500\u2500 images/ \u2502 \u251c\u2500\u2500 add_users.md \u2502 \u251c\u2500\u2500 assignments_on_github.md \u2502 \u251c\u2500\u2500 building_docs.md \u2502 \u251c\u2500\u2500 cookie_secret_proxy_auth_token.md \u2502 \u251c\u2500\u2500 custom_login_page.md \u2502 \u251c\u2500\u2500 dns_routing.md \u2502 \u251c\u2500\u2500 extra_configuration.md \u2502 \u251c\u2500\u2500 google_oauth.md \u2502 \u251c\u2500\u2500 index.md \u2502 \u251c\u2500\u2500 install_jupyterhub.md \u2502 \u251c\u2500\u2500 jupyterhub_config.md \u2502 \u251c\u2500\u2500 nbgitpuller_defaut_url.md \u2502 \u251c\u2500\u2500 nbgitpuller_plugin.md \u2502 \u251c\u2500\u2500 nginx_config.md \u2502 \u251c\u2500\u2500 nginx_install.md \u2502 \u251c\u2500\u2500 periodic_maintenance.md \u2502 \u251c\u2500\u2500 server_setup.md \u2502 \u251c\u2500\u2500 setup_and_tools.md \u2502 \u251c\u2500\u2500 slides \u2502 \u251c\u2500\u2500 ssh_keys.md \u2502 \u251c\u2500\u2500 ssl_cirtificates.md \u2502 \u251c\u2500\u2500 static \u2502 \u251c\u2500\u2500 systemd.md \u2502 \u251c\u2500\u2500 useful_commands.md \u2502 \u2514\u2500\u2500 what_is_jupyterhub.md \u2514\u2500\u2500 theme \u251c\u2500\u2500 assets \u2514\u2500\u2500 partials To build the docs locally, make sure you have Python installed (I use Anaconda ). Start out by cloning the repo: git clone https://github.com/ProfessorKazarinoff/jupyterhub-engr101.git cd into the cloned repo, and create a virtual environment. Install the Python packages needed to build the docs. cd jupyterhub-engr101.git conda create -n jupyterhub-docs python=3.7 conda activate jupyterhub-docs (jupyterhub-docs) pip install -r requirements-docs.txt cd into the docs dir, and run mkdocs build and mkdocs serve cd docs ls # mkdocs.yml mkdocs build mkdocs serve Look at the built site on local host: http://localhost:8000/ Deploy to GitHub pages mkdocs gh-deploy If the deployment returns an error, try the following command instead: mkdocs gh-deploy --force","title":"Building Docs"},{"location":"cookie_secret_proxy_auth_token/","text":"Create a Cookie Secret and Proxy Auth Token In addition to an SSL certificate, the Jupyter Hub docs on security basics specify that a cookie secret and poxy auth token should be created. Create a Cookie Secret and Proxy Auth Token Create the Cookie Secret Create Proxy Auth Token Create dhparam.pem Next Steps Create the Cookie Secret To create the cookie secret file, log onto the JupyterHub server and issue the following commands: $ cd /srv $ sudo mkdir jupyterhub $ cd jupyterhub $ sudo touch jupyterhub_cookie_secret $ sudo chown :sudo jupyterhub_cookie_secret $ sudo chmod g+rw jupyterhub_cookie_secret $ sudo openssl rand -hex 32 > jupyterhub_cookie_secret $ ls jupyterhub_cookie_secret $ sudo chmod 600 jupyterhub_cookie_secret $ ls -l -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret I had trouble with the cookie secret file because I missed where the JupyterHub docs show: The file must not be readable by group or other or the server won\u2019t start. The recommended permissions for the cookie secret file are 600 (owner-only rw). After we create the cookie secret file, we need to make note of the file's location. We'll add this file path to the jupyterhub_config.py file in a future step. Create Proxy Auth Token To generate the proxy auth token, use the same set of commands used to create the cookie secret, except point to a different file. $ pwd # should be in /srv/jupyterhub $ sudo touch proxy_auth_token $ sudo chown :sudo proxy_auth_token $ sudo chmod g+rw proxy_auth_token $ sudo openssl rand -hex 32 > proxy_auth_token $ ls jupyterhub_cookie_secret proxy_auth_token $ sudo chmod 600 proxy_auth_token $ ls -l -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Sep 14 17:47 proxy_auth_token Now when we list the contents of ~/srv/jupyterhub directory we see: /srv/jupyterhub/ \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token Create dhparam.pem Let's also generate a dhparam.pem file. I'm still not exactly sure what the dhparam.pem file is, but I think it's good for security. The dhparam.pem file will be housed in the same /srv/jupyterhub directory that stores our proxy auth token and cookie secret. We use the same commands that were used to create the previous two files: touch a new file called dhparam.pem , then use chown and chmod to modify permissions. The openssl dhparam command generates the .pem file. After the openssl dhparam command is run, a message appears: This is going to take a long time , but it doesn't really take all that long. Maybe a minute or two. Finally modify the permissions again to 600 (owner-only rw). Note the location of this file as we will add it to the Nginx config in a future step. $ cd /srv/jupyterhub $ sudo touch dhparam.pem $ sudo chown :sudo dhparam.pem $ sudo chmod g+rw dhparam.pem $ sudo openssl dhparam -out /srv/jupyterhub/dhparam.pem 2048 $ sudo chmod 600 dhparam.pem $ ls -l -rw------- 1 root sudo 424 Sep 14 17:59 dhparam.pem -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Sep 14 17:47 proxy_auth_token We now have three files in the /srv/jupyterhub/ directory. The jupyterhub_cookie_secret and proxy_auth_token will be referenced in the jupyterhub_config.py file. The dhparam.pem file will be referenced in the nginx.conf file. /srv/jupyterhub/ \u251c\u2500\u2500 dhparam.pem \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token Next Steps The next step is to install Nginx.","title":"Cookie Secret and Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-a-cookie-secret-and-proxy-auth-token","text":"In addition to an SSL certificate, the Jupyter Hub docs on security basics specify that a cookie secret and poxy auth token should be created. Create a Cookie Secret and Proxy Auth Token Create the Cookie Secret Create Proxy Auth Token Create dhparam.pem Next Steps","title":"Create a Cookie Secret and Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-the-cookie-secret","text":"To create the cookie secret file, log onto the JupyterHub server and issue the following commands: $ cd /srv $ sudo mkdir jupyterhub $ cd jupyterhub $ sudo touch jupyterhub_cookie_secret $ sudo chown :sudo jupyterhub_cookie_secret $ sudo chmod g+rw jupyterhub_cookie_secret $ sudo openssl rand -hex 32 > jupyterhub_cookie_secret $ ls jupyterhub_cookie_secret $ sudo chmod 600 jupyterhub_cookie_secret $ ls -l -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret I had trouble with the cookie secret file because I missed where the JupyterHub docs show: The file must not be readable by group or other or the server won\u2019t start. The recommended permissions for the cookie secret file are 600 (owner-only rw). After we create the cookie secret file, we need to make note of the file's location. We'll add this file path to the jupyterhub_config.py file in a future step.","title":"Create the Cookie Secret"},{"location":"cookie_secret_proxy_auth_token/#create-proxy-auth-token","text":"To generate the proxy auth token, use the same set of commands used to create the cookie secret, except point to a different file. $ pwd # should be in /srv/jupyterhub $ sudo touch proxy_auth_token $ sudo chown :sudo proxy_auth_token $ sudo chmod g+rw proxy_auth_token $ sudo openssl rand -hex 32 > proxy_auth_token $ ls jupyterhub_cookie_secret proxy_auth_token $ sudo chmod 600 proxy_auth_token $ ls -l -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Sep 14 17:47 proxy_auth_token Now when we list the contents of ~/srv/jupyterhub directory we see: /srv/jupyterhub/ \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token","title":"Create Proxy Auth Token"},{"location":"cookie_secret_proxy_auth_token/#create-dhparampem","text":"Let's also generate a dhparam.pem file. I'm still not exactly sure what the dhparam.pem file is, but I think it's good for security. The dhparam.pem file will be housed in the same /srv/jupyterhub directory that stores our proxy auth token and cookie secret. We use the same commands that were used to create the previous two files: touch a new file called dhparam.pem , then use chown and chmod to modify permissions. The openssl dhparam command generates the .pem file. After the openssl dhparam command is run, a message appears: This is going to take a long time , but it doesn't really take all that long. Maybe a minute or two. Finally modify the permissions again to 600 (owner-only rw). Note the location of this file as we will add it to the Nginx config in a future step. $ cd /srv/jupyterhub $ sudo touch dhparam.pem $ sudo chown :sudo dhparam.pem $ sudo chmod g+rw dhparam.pem $ sudo openssl dhparam -out /srv/jupyterhub/dhparam.pem 2048 $ sudo chmod 600 dhparam.pem $ ls -l -rw------- 1 root sudo 424 Sep 14 17:59 dhparam.pem -rw------- 1 root sudo 65 Sep 14 17:41 jupyterhub_cookie_secret -rw------- 1 root sudo 65 Sep 14 17:47 proxy_auth_token We now have three files in the /srv/jupyterhub/ directory. The jupyterhub_cookie_secret and proxy_auth_token will be referenced in the jupyterhub_config.py file. The dhparam.pem file will be referenced in the nginx.conf file. /srv/jupyterhub/ \u251c\u2500\u2500 dhparam.pem \u251c\u2500\u2500 jupyterhub_cookie_secret \u2514\u2500\u2500 proxy_auth_token","title":"Create dhparam.pem"},{"location":"cookie_secret_proxy_auth_token/#next-steps","text":"The next step is to install Nginx.","title":"Next Steps"},{"location":"cull_idle_servers/","text":"Cull Idle Servers In this section, we will go over some extra configuration settings we can set in jupyterhub_config.py to help our JupyterHub deployment hum along and help if students forget to logout or too many student try and log in at the same time. Cull Idle Servers Configuration Options Cull Idle Servers Modify jupyterhub_config.py and upload to server Summary Additional Extras Configuration Options In the JupyterHub docs, there is a list of configuration options and descriptions: https://jupyterhub.readthedocs.io/en/stable/api/app.html A couple configuration options in the list seem like good ideas: The class has 24 students, plus one instructor. Given that class size, I think 26 is a good number for the maximum that can use JupyterHub the same time. config c.JupyterHub.active_server_limit = Int(0) # Maximum number of concurrent servers that can be active at a time. Having too many users log in all at the same time can overload the server. Let's set this as 13, so half of the class can log in at the same time. config c.JupyterHub.concurrent_spawn_limit = Int(100) Maximum number of concurrent users that can be spawning at a time. A couple settings relate to shutting down the hub and if user servers shut down too. I want it set so that if I shut down the hub, all the user servers are shut down too. config c.JupyterHub.cleanup_proxy = Bool(True) # Whether to shutdown the proxy when the Hub shuts down. config c.JupyterHub.cleanup_servers = Bool(True) # Whether to shutdown single-user servers when the Hub shuts down. Cull Idle Servers A problem with the first two JupyterHub deployments was that some students would not shut down their server when they were done working. Then twenty or so servers would all keep running all the time. This script from the JupyterHub Examples repo looks like it might help: https://github.com/jupyterhub/jupyterhub/tree/master/examples/cull-idle To get the cull_idle_servers.py script to run as a JupyterHub service, it looks like you need to add the following to jupyterhub_config.py . (Based on this page in the JupyterHub docs) # /etc/jupyterhub/jupyterhub_config.py import sys ... # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] Put cull_idle_servers.py (found here ) in /etc/jupyterhub/ . Make sure dateutil is intalled in the jupyterhub virtual env. Try >>> import dateutil >>> dateutil.__version__ (using the (jupyterhub) virtual env. Make sure to add import sys to the top of jupyterhub_config.py . Restart JupyterHub. Check for errors. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit If it seems like the cull_idle_servers.py script isn't working, try running cull_idle_servers.py from the command line to see if there are any errors. Make sure you are in the (jupyterhub) virtual environment when you run the script. The script will look for the JUPYTERHUB_API_TOKEN environment variable. An API token can be aquired by logging into JupyterHub (like a regular student) and clicking the [Token] menu from the home page that has the [Stop My Server] and [My Server] buttons. Click [Request new API token] and copy the API token. Then run the lines below (replace ```XXXX```` with your actual API token): $ export JUPYTERHUB_API_TOKEN='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' $ echo $JUPYTERHUB_API_TOKEN # API token is printed $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ python cull_idle_servers.py --timeout=60 --url=http://127.0.0.1:8081/hub/api # check for errors Modify jupyterhub_config.py and upload to server The additions made to jupyterhub_config.py are shown below: # /etc/jupyterhub/jupyterhub_config.py ... ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] ... I made these changes in jupyterhub_config.py locally and then used FileZilla to upload the modified config file to the server. After the modified jupyterhub_config.py file is uploaded to the server, restart JupyterHub and make sure there no errors. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Summary In this section we added a few extra configuration options to the jupyterhub_config.py file. A few extra configuration options we included were to limit the number of servers that can run at the same time and limit the amount of servers that can spawn at the same time. We also added a cull_idle_servers.py script to the server which will shut down idle servers if a student has not used them in a while. This involved copying the script locally from GitHub, then uploading the script on the server in the /etc/jupyterhub/ directory. The jupyterhub_config.py file has to be modified so that sys is imported and the cull_idle_servers.py script runs and a JupyterHub service Finally we uploaded the modified jupyterhubconfig.py configuration file and restarted JupyterHub. Additional Extras That's it for the main JupyterHub deployment! The next section is about periodic maintenance. After running JupyterHub for two quarters there are a couple lessons learned server regarding maintenance.","title":"Cull Idle Servers"},{"location":"cull_idle_servers/#cull-idle-servers","text":"In this section, we will go over some extra configuration settings we can set in jupyterhub_config.py to help our JupyterHub deployment hum along and help if students forget to logout or too many student try and log in at the same time. Cull Idle Servers Configuration Options Cull Idle Servers Modify jupyterhub_config.py and upload to server Summary Additional Extras","title":"Cull Idle Servers"},{"location":"cull_idle_servers/#configuration-options","text":"In the JupyterHub docs, there is a list of configuration options and descriptions: https://jupyterhub.readthedocs.io/en/stable/api/app.html A couple configuration options in the list seem like good ideas: The class has 24 students, plus one instructor. Given that class size, I think 26 is a good number for the maximum that can use JupyterHub the same time. config c.JupyterHub.active_server_limit = Int(0) # Maximum number of concurrent servers that can be active at a time. Having too many users log in all at the same time can overload the server. Let's set this as 13, so half of the class can log in at the same time. config c.JupyterHub.concurrent_spawn_limit = Int(100) Maximum number of concurrent users that can be spawning at a time. A couple settings relate to shutting down the hub and if user servers shut down too. I want it set so that if I shut down the hub, all the user servers are shut down too. config c.JupyterHub.cleanup_proxy = Bool(True) # Whether to shutdown the proxy when the Hub shuts down. config c.JupyterHub.cleanup_servers = Bool(True) # Whether to shutdown single-user servers when the Hub shuts down.","title":"Configuration Options"},{"location":"cull_idle_servers/#cull-idle-servers_1","text":"A problem with the first two JupyterHub deployments was that some students would not shut down their server when they were done working. Then twenty or so servers would all keep running all the time. This script from the JupyterHub Examples repo looks like it might help: https://github.com/jupyterhub/jupyterhub/tree/master/examples/cull-idle To get the cull_idle_servers.py script to run as a JupyterHub service, it looks like you need to add the following to jupyterhub_config.py . (Based on this page in the JupyterHub docs) # /etc/jupyterhub/jupyterhub_config.py import sys ... # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] Put cull_idle_servers.py (found here ) in /etc/jupyterhub/ . Make sure dateutil is intalled in the jupyterhub virtual env. Try >>> import dateutil >>> dateutil.__version__ (using the (jupyterhub) virtual env. Make sure to add import sys to the top of jupyterhub_config.py . Restart JupyterHub. Check for errors. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit If it seems like the cull_idle_servers.py script isn't working, try running cull_idle_servers.py from the command line to see if there are any errors. Make sure you are in the (jupyterhub) virtual environment when you run the script. The script will look for the JUPYTERHUB_API_TOKEN environment variable. An API token can be aquired by logging into JupyterHub (like a regular student) and clicking the [Token] menu from the home page that has the [Stop My Server] and [My Server] buttons. Click [Request new API token] and copy the API token. Then run the lines below (replace ```XXXX```` with your actual API token): $ export JUPYTERHUB_API_TOKEN='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' $ echo $JUPYTERHUB_API_TOKEN # API token is printed $ cd /etc/jupyterhub $ conda activate jupyterhub (jupyterhub)$ python cull_idle_servers.py --timeout=60 --url=http://127.0.0.1:8081/hub/api # check for errors","title":"Cull Idle Servers"},{"location":"cull_idle_servers/#modify-jupyterhub_configpy-and-upload-to-server","text":"The additions made to jupyterhub_config.py are shown below: # /etc/jupyterhub/jupyterhub_config.py ... ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True # Cull Idle Servers # place cull_idle_servers.py in /etc/jupyterhub c.JupyterHub.services = [ { 'name': 'cull-idle', 'admin': True, 'command': [sys.executable, '/etc/jupyterhub/cull_idle_servers.py', '--timeout=3000', '--url=http://127.0.0.1:8081/hub/api' ], } ] ... I made these changes in jupyterhub_config.py locally and then used FileZilla to upload the modified config file to the server. After the modified jupyterhub_config.py file is uploaded to the server, restart JupyterHub and make sure there no errors. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit","title":"Modify jupyterhub_config.py and upload to server"},{"location":"cull_idle_servers/#summary","text":"In this section we added a few extra configuration options to the jupyterhub_config.py file. A few extra configuration options we included were to limit the number of servers that can run at the same time and limit the amount of servers that can spawn at the same time. We also added a cull_idle_servers.py script to the server which will shut down idle servers if a student has not used them in a while. This involved copying the script locally from GitHub, then uploading the script on the server in the /etc/jupyterhub/ directory. The jupyterhub_config.py file has to be modified so that sys is imported and the cull_idle_servers.py script runs and a JupyterHub service Finally we uploaded the modified jupyterhubconfig.py configuration file and restarted JupyterHub.","title":"Summary"},{"location":"cull_idle_servers/#additional-extras","text":"That's it for the main JupyterHub deployment! The next section is about periodic maintenance. After running JupyterHub for two quarters there are a couple lessons learned server regarding maintenance.","title":"Additional Extras"},{"location":"doserver/","text":"Set Up Digital Ocean Server To start the JupyterHub deployment process, we need to set up an Ubuntu 18.04 Server hosted by a cloud provider. Set Up Digital Ocean Server Create a new Digital Ocean Droplet Add an SSH Key Log into the server as root over SSH using PuTTY. Create a non-root sudo user Add SSH keys to new user's profile Connect to the server as the non-root sudo user using PuTTY Next Steps Digital Ocean is a cloud service provider like Amazon Web Services (AWS), Google Cloud, Microsoft Azure and Linode. Digital Ocean provides virtual private servers (called droplets in Digital Ocean-speak) and online storage of static files (called spaces in Digital Ocean-speak). We are going to run JupyterHub on a Digital Ocean droplet . I like Digital Ocean's prices and web interface. The documentation on Digital Ocean is pretty good too. I already have a Digital Ocean account. I don't remember exactly how I did it, but going to this link: https://www.digitalocean.com/ and selecting [Create Account \u2192] should work. Create a new Digital Ocean Droplet To create a new Digtial Ocean droplet (a new cloud server), log in here: https://cloud.digitalocean.com/login After logging in, I got a verify screen and had to go to my email and retrive a six digit code. Ah... the joys of two-factor authentication. The welcome screen looks like this. To create a new server, select [Create Droplet] There are a number of choices to make when you initially set up your server. The specifications I selected are below. Afer the server is set up, the amount of memory and processor count can be changed. Image: Ubuntu 18.04 x64 Size: 1 GB Memory 25GB SSD $5/month Datacenter: San Fransisco 2 Add your SSH keys: New SSH Key Finalize: 1 Droplet, Hostname: jupyterhub-engr114 Add an SSH Key Warning Important! You need to add the public SSH key BEFORE creating the droplet The public SSH key we created needs to be shown on the list of keys and the radio box beside it needs to be checked. If the SSH key isn't listed or the SSH key box left unchecked, the SSH key will not be added to the server when the server is first created (and then we won't be able to log in with PuTTY). We need to add our public SSH key and check the key box so we can log onto the server with PuTTY. Under [Add your SSH keys], click [New SSH Key]. A dialog window pops up: Paste the contents of the public SSH key into the [New SSH Key] dialog box. Enter a name for the SSH key that will be saved on Digital Ocean. I choose the name jupyter-hub-ssh-key . Then click [Add SSH Key] Then you should see the new SSH Key in the [Add your SSH Keys] region of the new droplets page. Make sure that the radio box for the SSH key we just added is checked. A problem I had when I set up my first droplet was that I did not have the SSH Key was radio button selected. Therefore, when the server was created, no SSH keys were installed. It is way easier to insert SSH keys into the server when the server is created. It is way harder to add an SSH keys after the server is created. Click the long green [Create] button at the bottom of the page to create the Droplet. After Droplet creation, you end up at the Digital Ocean main dashboard. Our new Droplet can be seen under [Resources] \u2192 [Droplets]. Note and copy the IP address of the new droplet to the clipboard. We need to IP address to log into our server with PuTTY. Log into the server as root over SSH using PuTTY. Open PuTTY from the Windows start menu. Set the following parameters in PuTTY to log into the server. parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username root Under Connect \u2192 SSH \u2192 Auth \u2192 Private key file for authentication:, click [Browse]. Navigate to the SSH private key. The private key ends in a .ppk extension. I had trouble finding the key when I first set up PuTTY. It turned out that when the key was saved in the Programfiles\\PuTTY folder. The key was not visible in the Windows file browser because I don't have administrator permissions on my machine at work. I ended up having to create a new SSH key and save the new key in Documents\\ssh-key (I can access Documents\\ssh-key without administrator privaleges). Under Connection \u2192 Data \u2192 Auto-login username: root Back in [Sessions] (the top-most menu item or main page), add the IP address and Port = 22, click [Open] This brings up a new window that is a terminal for our server: Create a non-root sudo user Digital Ocean recommends that servers are run by a non-root user that has sudo access. So after an update, the thing we'll do on our server is create a non-root sudo user. First, let's make sure everything is up to date: # apt-get update # sudo apt-get upgrade I followed this tutorial at Digital Ocean to create a non-root sudo user. Create the new user with the adduser command. I called my new user peter . # adduser peter Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] Now let's give our new user sudo privaleges: # usermod -aG sudo peter The new user account is created and the new user has sudo privalges. We can switch accounts and become the new user with: # su - peter The new user should have sudo privileges. That means when acting as peter we should be able to look in the /root directory. $ sudo ls -la /root If you can see the contents of /root then the new user is set up with sudo access. To exit out of the the new sudo user, and get back to using the root profile, type exit at the prompt. $ exit # Add SSH keys to new user's profile Before we log off, we need to add our SSH keys to our new user's profile on the server. The second time I set up JupyterHub, I had trouble logging in as the non-root user using PuTTY. I could log in as root just fine, but I couldn't log in as the newly created user peter . When Digital Ocean created the server, the SSH keys (specified on the creation page) were added to the root profile. The new user peter didn't exist when the server was created. The only user on the server at creation time was root . Therefore, no SSH keys were added to the peter profile at server creation time- because the user peter didn't exist yet. Since we want to log into our server as the new non-root user peter , we need to add the same SSH keys saved in the root profile to the peter profile. The SSH keys belong in a file located at /home/peter/.ssh/authorized_keys . This little line will copy the ssh keys from the root profile to the new user's profile. The line comes from this tutorial by Digital Ocean. $ rsync --archive --chown=peter:peter ~/.ssh /home/peter Next, we need to open the ufw firewall to OpenSSH trafic. We we'll communicate with the server over SSH and need the firewall to allow this type of communication through. $ sudo ufw allow OpenSSH $ sudo ufw enable $ sudo ufw status Now we can exit out of the root profile. This terminates the PuTTY session. $ exit Connect to the server as the non-root sudo user using PuTTY Now that the non-root sudo user is set up and our ssh keys are in /home/peter/.ssh/authorized_keys/ , let's start a new PuTTY session and log into the server as the new user peter . Like before, open PuTTY from the Windows Start menu and add the following settings, but this time the Auto-login user name is the name of our new non-root sudo user: parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username peter I also saved the PuTTY session details at this point so that I wouldn't have to re-enter all of the parameters each time I want to log into the server. Enter a name into [Saved Sessions] and click [Save]. Once the parameters are saved in PuTTY, you can simply double-click the profile name to log into the server. Log into the server with Sessions \u2192 [Open] You should see the Digital Ocean login screen again. Note the command prompt will have the new user's name before the @ symbol. Check to see which directory you land in. It should be /home/peter $ pwd /home/peter Let's make sure we can also see into the root user's home directory to ensure we have sudo privileges as the non-root user: $ sudo ls -la /root To log out of the server simply type exit . This command closes the PuTTY session. $ exit Next Steps The next step is to install Miniconda , create a virtual environment, and install JupyterHub .","title":"Server Setup"},{"location":"doserver/#set-up-digital-ocean-server","text":"To start the JupyterHub deployment process, we need to set up an Ubuntu 18.04 Server hosted by a cloud provider. Set Up Digital Ocean Server Create a new Digital Ocean Droplet Add an SSH Key Log into the server as root over SSH using PuTTY. Create a non-root sudo user Add SSH keys to new user's profile Connect to the server as the non-root sudo user using PuTTY Next Steps Digital Ocean is a cloud service provider like Amazon Web Services (AWS), Google Cloud, Microsoft Azure and Linode. Digital Ocean provides virtual private servers (called droplets in Digital Ocean-speak) and online storage of static files (called spaces in Digital Ocean-speak). We are going to run JupyterHub on a Digital Ocean droplet . I like Digital Ocean's prices and web interface. The documentation on Digital Ocean is pretty good too. I already have a Digital Ocean account. I don't remember exactly how I did it, but going to this link: https://www.digitalocean.com/ and selecting [Create Account \u2192] should work.","title":"Set Up Digital Ocean Server"},{"location":"doserver/#create-a-new-digital-ocean-droplet","text":"To create a new Digtial Ocean droplet (a new cloud server), log in here: https://cloud.digitalocean.com/login After logging in, I got a verify screen and had to go to my email and retrive a six digit code. Ah... the joys of two-factor authentication. The welcome screen looks like this. To create a new server, select [Create Droplet] There are a number of choices to make when you initially set up your server. The specifications I selected are below. Afer the server is set up, the amount of memory and processor count can be changed. Image: Ubuntu 18.04 x64 Size: 1 GB Memory 25GB SSD $5/month Datacenter: San Fransisco 2 Add your SSH keys: New SSH Key Finalize: 1 Droplet, Hostname: jupyterhub-engr114","title":"Create a new Digital Ocean Droplet"},{"location":"doserver/#add-an-ssh-key","text":"Warning Important! You need to add the public SSH key BEFORE creating the droplet The public SSH key we created needs to be shown on the list of keys and the radio box beside it needs to be checked. If the SSH key isn't listed or the SSH key box left unchecked, the SSH key will not be added to the server when the server is first created (and then we won't be able to log in with PuTTY). We need to add our public SSH key and check the key box so we can log onto the server with PuTTY. Under [Add your SSH keys], click [New SSH Key]. A dialog window pops up: Paste the contents of the public SSH key into the [New SSH Key] dialog box. Enter a name for the SSH key that will be saved on Digital Ocean. I choose the name jupyter-hub-ssh-key . Then click [Add SSH Key] Then you should see the new SSH Key in the [Add your SSH Keys] region of the new droplets page. Make sure that the radio box for the SSH key we just added is checked. A problem I had when I set up my first droplet was that I did not have the SSH Key was radio button selected. Therefore, when the server was created, no SSH keys were installed. It is way easier to insert SSH keys into the server when the server is created. It is way harder to add an SSH keys after the server is created. Click the long green [Create] button at the bottom of the page to create the Droplet. After Droplet creation, you end up at the Digital Ocean main dashboard. Our new Droplet can be seen under [Resources] \u2192 [Droplets]. Note and copy the IP address of the new droplet to the clipboard. We need to IP address to log into our server with PuTTY.","title":"Add an SSH Key"},{"location":"doserver/#log-into-the-server-as-root-over-ssh-using-putty","text":"Open PuTTY from the Windows start menu. Set the following parameters in PuTTY to log into the server. parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username root Under Connect \u2192 SSH \u2192 Auth \u2192 Private key file for authentication:, click [Browse]. Navigate to the SSH private key. The private key ends in a .ppk extension. I had trouble finding the key when I first set up PuTTY. It turned out that when the key was saved in the Programfiles\\PuTTY folder. The key was not visible in the Windows file browser because I don't have administrator permissions on my machine at work. I ended up having to create a new SSH key and save the new key in Documents\\ssh-key (I can access Documents\\ssh-key without administrator privaleges). Under Connection \u2192 Data \u2192 Auto-login username: root Back in [Sessions] (the top-most menu item or main page), add the IP address and Port = 22, click [Open] This brings up a new window that is a terminal for our server:","title":"Log into the server as root over SSH using PuTTY."},{"location":"doserver/#create-a-non-root-sudo-user","text":"Digital Ocean recommends that servers are run by a non-root user that has sudo access. So after an update, the thing we'll do on our server is create a non-root sudo user. First, let's make sure everything is up to date: # apt-get update # sudo apt-get upgrade I followed this tutorial at Digital Ocean to create a non-root sudo user. Create the new user with the adduser command. I called my new user peter . # adduser peter Set a new password and confirm: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfully The user details can be skipped by pressing [Enter]. Then [Y] to complete the new user setup. Changing the user information for username Enter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] Now let's give our new user sudo privaleges: # usermod -aG sudo peter The new user account is created and the new user has sudo privalges. We can switch accounts and become the new user with: # su - peter The new user should have sudo privileges. That means when acting as peter we should be able to look in the /root directory. $ sudo ls -la /root If you can see the contents of /root then the new user is set up with sudo access. To exit out of the the new sudo user, and get back to using the root profile, type exit at the prompt. $ exit #","title":"Create a non-root sudo user"},{"location":"doserver/#add-ssh-keys-to-new-users-profile","text":"Before we log off, we need to add our SSH keys to our new user's profile on the server. The second time I set up JupyterHub, I had trouble logging in as the non-root user using PuTTY. I could log in as root just fine, but I couldn't log in as the newly created user peter . When Digital Ocean created the server, the SSH keys (specified on the creation page) were added to the root profile. The new user peter didn't exist when the server was created. The only user on the server at creation time was root . Therefore, no SSH keys were added to the peter profile at server creation time- because the user peter didn't exist yet. Since we want to log into our server as the new non-root user peter , we need to add the same SSH keys saved in the root profile to the peter profile. The SSH keys belong in a file located at /home/peter/.ssh/authorized_keys . This little line will copy the ssh keys from the root profile to the new user's profile. The line comes from this tutorial by Digital Ocean. $ rsync --archive --chown=peter:peter ~/.ssh /home/peter Next, we need to open the ufw firewall to OpenSSH trafic. We we'll communicate with the server over SSH and need the firewall to allow this type of communication through. $ sudo ufw allow OpenSSH $ sudo ufw enable $ sudo ufw status Now we can exit out of the root profile. This terminates the PuTTY session. $ exit","title":"Add SSH keys to new user's profile"},{"location":"doserver/#connect-to-the-server-as-the-non-root-sudo-user-using-putty","text":"Now that the non-root sudo user is set up and our ssh keys are in /home/peter/.ssh/authorized_keys/ , let's start a new PuTTY session and log into the server as the new user peter . Like before, open PuTTY from the Windows Start menu and add the following settings, but this time the Auto-login user name is the name of our new non-root sudo user: parameter value IP Address IP of droplet ex: 168.97.14.19 Port 22 Connection \u2192 SSH \u2192 Auth \u2192 Private key file private SSH key Connection \u2192 Data \u2192 Auto-login username peter I also saved the PuTTY session details at this point so that I wouldn't have to re-enter all of the parameters each time I want to log into the server. Enter a name into [Saved Sessions] and click [Save]. Once the parameters are saved in PuTTY, you can simply double-click the profile name to log into the server. Log into the server with Sessions \u2192 [Open] You should see the Digital Ocean login screen again. Note the command prompt will have the new user's name before the @ symbol. Check to see which directory you land in. It should be /home/peter $ pwd /home/peter Let's make sure we can also see into the root user's home directory to ensure we have sudo privileges as the non-root user: $ sudo ls -la /root To log out of the server simply type exit . This command closes the PuTTY session. $ exit","title":"Connect to the server as the non-root sudo user using PuTTY"},{"location":"doserver/#next-steps","text":"The next step is to install Miniconda , create a virtual environment, and install JupyterHub .","title":"Next Steps"},{"location":"draw_dot_IO_extension/","text":"Draw.IO Extension In ENGR114, students will learn how to construct flow charts that describe the way a program runs. They will also use flowcharts to plan how a program will run. We can provide students with access to a flow chart drawing program right in JupyterHub called Draw.IO. Draw.IO will be added to our JuptyerHub deployment as a JupyterLab extension. Draw.IO Extension Install nodejs Install Draw.IO extension for JupyterLub Restart JupyterHub and test it out Summary Install nodejs Ensure that nodejs is intalled in the (jupyterhubenv) virtual environment. Nodejs is needed to install the Draw.IO JupyterLab extension. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ conda install -c conda-forge nodejs Install Draw.IO extension for JupyterLub Another conda install line to install the Draw.IO extension for JupyterLab. (jupyterhubenv)$ jupyter labextension install jupyterlab-drawio Restart JupyterHub and test it out $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit Summary This page showed how to install the Draw.IO extension for JupyterLab. JupyterHub users the open the JupyterLab interface can use Draw.IO to create flow charts and other useful diagrmas.","title":"Draw.IO extension"},{"location":"draw_dot_IO_extension/#drawio-extension","text":"In ENGR114, students will learn how to construct flow charts that describe the way a program runs. They will also use flowcharts to plan how a program will run. We can provide students with access to a flow chart drawing program right in JupyterHub called Draw.IO. Draw.IO will be added to our JuptyerHub deployment as a JupyterLab extension. Draw.IO Extension Install nodejs Install Draw.IO extension for JupyterLub Restart JupyterHub and test it out Summary","title":"Draw.IO Extension"},{"location":"draw_dot_IO_extension/#install-nodejs","text":"Ensure that nodejs is intalled in the (jupyterhubenv) virtual environment. Nodejs is needed to install the Draw.IO JupyterLab extension. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ conda install -c conda-forge nodejs","title":"Install nodejs"},{"location":"draw_dot_IO_extension/#install-drawio-extension-for-jupyterlub","text":"Another conda install line to install the Draw.IO extension for JupyterLab. (jupyterhubenv)$ jupyter labextension install jupyterlab-drawio","title":"Install Draw.IO extension for JupyterLub"},{"location":"draw_dot_IO_extension/#restart-jupyterhub-and-test-it-out","text":"$ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit","title":"Restart JupyterHub and test it out"},{"location":"draw_dot_IO_extension/#summary","text":"This page showed how to install the Draw.IO extension for JupyterLab. JupyterHub users the open the JupyterLab interface can use Draw.IO to create flow charts and other useful diagrmas.","title":"Summary"},{"location":"github_extension/","text":"GitHub Extension You can put in a \"GitHub\" tab into each user's JupyterLab browser that shows a \"labs\" and \"notes\" directory with pre-constructed lab assignments and notes for each JupyterHub user. GitHub Extension Install nodejs Install GitHub extension for JupyterLub Restart JupyterHub and test it out Create notebook config file Aquire GitHub token Modify notebook config file pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub A way to put a default repo in? Install nodejs To install the GitHub extension for JupyterHub, first log into the server and install nodejs with conda into the (jupyterhubenv) virtual environment. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ conda install -c conda-forge nodejs Install GitHub extension for JupyterLub Another conda install line to install the GitHub extension for JupyterLab. (jupyterhubenv)$ jupyter labextension install @jupyterlab/github Restart JupyterHub and test it out $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit Create notebook config file Aquire GitHub token Modify notebook config file pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub A way to put a default repo in? In the notebook config file (not the jupyterhub config file): c.GitHubConfig.api_url = 'https://git.myserver.com/api/v3'","title":"GitHub Extension for JupyterLab"},{"location":"github_extension/#github-extension","text":"You can put in a \"GitHub\" tab into each user's JupyterLab browser that shows a \"labs\" and \"notes\" directory with pre-constructed lab assignments and notes for each JupyterHub user. GitHub Extension Install nodejs Install GitHub extension for JupyterLub Restart JupyterHub and test it out Create notebook config file Aquire GitHub token Modify notebook config file pip install GitHub server extension Point JupyterHub to notebook config file Restart JupyterHub A way to put a default repo in?","title":"GitHub Extension"},{"location":"github_extension/#install-nodejs","text":"To install the GitHub extension for JupyterHub, first log into the server and install nodejs with conda into the (jupyterhubenv) virtual environment. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ conda install -c conda-forge nodejs","title":"Install nodejs"},{"location":"github_extension/#install-github-extension-for-jupyterlub","text":"Another conda install line to install the GitHub extension for JupyterLab. (jupyterhubenv)$ jupyter labextension install @jupyterlab/github","title":"Install GitHub extension for JupyterLub"},{"location":"github_extension/#restart-jupyterhub-and-test-it-out","text":"$ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit","title":"Restart JupyterHub and test it out"},{"location":"github_extension/#create-notebook-config-file","text":"","title":"Create notebook config file"},{"location":"github_extension/#aquire-github-token","text":"","title":"Aquire GitHub token"},{"location":"github_extension/#modify-notebook-config-file","text":"","title":"Modify notebook config file"},{"location":"github_extension/#pip-install-github-server-extension","text":"","title":"pip install GitHub server extension"},{"location":"github_extension/#point-jupyterhub-to-notebook-config-file","text":"","title":"Point JupyterHub to notebook config file"},{"location":"github_extension/#restart-jupyterhub","text":"","title":"Restart JupyterHub"},{"location":"github_extension/#a-way-to-put-a-default-repo-in","text":"In the notebook config file (not the jupyterhub config file): c.GitHubConfig.api_url = 'https://git.myserver.com/api/v3'","title":"A way to put a default repo in?"},{"location":"github_oauth/","text":"GitHub Authentication JuptyerHub is working, but a problem is that we have to add new users(students) to the serever manually. It would be better if users could log in to JupyterHub with their own usernames and passwords. It would also be nice to not have to manage any of these usernames or passwords. One solution to this problem is have students log into JupyterHub with GitHub usernames and passwords. GitHub Authentication Install oauthenticator Create GitHub OAuth App Modify jupyterhub_config.py to use GitHub OAuth Restart JupyterHub and login with GitHub Summary In the current setup, users (students) have to be added to the JupyterHub server before they can log in. This is OK for a small team or a couple users, but for a college class, creating a new user on the server for each student, then emailing each student a seperate username and password... Ah! what a mess. One solution is to give JupyterHub the authority to create new users on the server. Then allow users (students) to login to JupyterHub with usernames and passwords they already have. One of the ways students could log into JupyterHub is using their GitHub credentials. This solution requires each student to have a GitHub account. A GitHub account for each student might be worth it. A benefit is a GitHub account gives students exposure to git and GitHub as a tools. So let's give the GitHub authenticator for JupyterHub a whirl. The GitHub authenticator is also pretty well documented, so it's good authenticator to try first. Install oauthenticator To use the GitHub authenticator in JupyterHub, first we need to install oauthenticator . I couldn't find oauthenticator on conda-forge so I installed it with pip . Remember we need to be in the (jupyterhubenv) virtual environment when we run the pip command. $ conda activate jupyterhubenv (jupyterhubenv)$ pip install oauthenticator Create GitHub OAuth App Next we need to log into GitHub and create an OAuth App. After the GitHub OAuth App is created, copy the Client ID and Client Secret . The processes is: GitHub profile \u2192 Settings \u2192 Developer Settings \u2192 OAuth Apps \u2192 Register a new application Set the Homepage URL as: https://mydomain.org/ Set the Authorization call-back URL as: https://mydomain.org/hub/oauth_callback Then click [Register Application] In the App Settings page, we need to copy two settings: Client ID Client Secret The Client ID and Client Secret strings will be pasted into the jupyterhub_config.py file. Modify jupyterhub_config.py to use GitHub OAuth Now we'll edit the jupyterhub_config.py file to include a couple additional lines. Note in the configuration below, #c.Authenticator.whitelist is commented out. We want to see if a GitHub user can log onto the server (which will automatically create a new user and spawn a Jupyter notebook server) and run notebooks. Once we know the server is working, we can un-comment the #c.Authenticator.whitelist and only allow in specific GitHub usernames. Also Note c.LocalGitHubOAuthenticator.client_id = 'xxxx' and c.LocalGitHubOAuthenticator.client_secret='xxxx' are the long strings from our GitHub OAuth App. # /etc/jupyterhub/jupyterhub_conf.py # Configuration file for JupyterHub to run GitHub OAuth. # Need to get client ID and client secret from GitHub --> User Settings --> Developer Settings --> OAuth Apps # also need to pip install oauthenticator from oauthenticator.github import LocalGitHubOAuthenticator c.JupyterHub.authenticator_class = LocalGitHubOAuthenticator # Set up config c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # GitHub OAuth Login c.LocalGitHubOAuthenticator.oauth_callback_url = 'https://mydomain.org/hub/oauth_callback' c.LocalGitHubOAuthenticator.client_id = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXX' c.LocalGitHubOAuthenticator.client_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' c.LocalGitHubOAuthenticator.create_system_users = True #c.Authenticator.whitelist = {'peter','username1','username2'} c.Authenticator.admin_users = {'peter'} Restart JupyterHub and login with GitHub Restart JupyterHub with: $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Browse over to our server's URL. We see [Sign in with GitHub] in the middle of the page. Log into JupyterHub with a GitHub username and password. After we log in using a GitHub username and password, we can see if JupyterHub created a new user (with our GitHub username) on the server. The command below produces a long list of users. The long list of users contains the non-root sudo user peter and the GitHub user. $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter githubusername We can also verify the GitHub user logged in by going to the /home/ directory on the server. Inside of /home/ should be a home directory for the GitHub user. Inside the GitHub user's directory are any notebooks we just created after we logged in with our GitHub credentials. $ cd /home $ ls peter githubusername $ cd githubusername $ ls Untitled.ipynb Summary This page documented how to use GitHub usernames and passwords to authenticate with JupyterHub.","title":"GitHub Authentication"},{"location":"github_oauth/#github-authentication","text":"JuptyerHub is working, but a problem is that we have to add new users(students) to the serever manually. It would be better if users could log in to JupyterHub with their own usernames and passwords. It would also be nice to not have to manage any of these usernames or passwords. One solution to this problem is have students log into JupyterHub with GitHub usernames and passwords. GitHub Authentication Install oauthenticator Create GitHub OAuth App Modify jupyterhub_config.py to use GitHub OAuth Restart JupyterHub and login with GitHub Summary In the current setup, users (students) have to be added to the JupyterHub server before they can log in. This is OK for a small team or a couple users, but for a college class, creating a new user on the server for each student, then emailing each student a seperate username and password... Ah! what a mess. One solution is to give JupyterHub the authority to create new users on the server. Then allow users (students) to login to JupyterHub with usernames and passwords they already have. One of the ways students could log into JupyterHub is using their GitHub credentials. This solution requires each student to have a GitHub account. A GitHub account for each student might be worth it. A benefit is a GitHub account gives students exposure to git and GitHub as a tools. So let's give the GitHub authenticator for JupyterHub a whirl. The GitHub authenticator is also pretty well documented, so it's good authenticator to try first.","title":"GitHub Authentication"},{"location":"github_oauth/#install-oauthenticator","text":"To use the GitHub authenticator in JupyterHub, first we need to install oauthenticator . I couldn't find oauthenticator on conda-forge so I installed it with pip . Remember we need to be in the (jupyterhubenv) virtual environment when we run the pip command. $ conda activate jupyterhubenv (jupyterhubenv)$ pip install oauthenticator","title":"Install oauthenticator"},{"location":"github_oauth/#create-github-oauth-app","text":"Next we need to log into GitHub and create an OAuth App. After the GitHub OAuth App is created, copy the Client ID and Client Secret . The processes is: GitHub profile \u2192 Settings \u2192 Developer Settings \u2192 OAuth Apps \u2192 Register a new application Set the Homepage URL as: https://mydomain.org/ Set the Authorization call-back URL as: https://mydomain.org/hub/oauth_callback Then click [Register Application] In the App Settings page, we need to copy two settings: Client ID Client Secret The Client ID and Client Secret strings will be pasted into the jupyterhub_config.py file.","title":"Create GitHub OAuth App"},{"location":"github_oauth/#modify-jupyterhub_configpy-to-use-github-oauth","text":"Now we'll edit the jupyterhub_config.py file to include a couple additional lines. Note in the configuration below, #c.Authenticator.whitelist is commented out. We want to see if a GitHub user can log onto the server (which will automatically create a new user and spawn a Jupyter notebook server) and run notebooks. Once we know the server is working, we can un-comment the #c.Authenticator.whitelist and only allow in specific GitHub usernames. Also Note c.LocalGitHubOAuthenticator.client_id = 'xxxx' and c.LocalGitHubOAuthenticator.client_secret='xxxx' are the long strings from our GitHub OAuth App. # /etc/jupyterhub/jupyterhub_conf.py # Configuration file for JupyterHub to run GitHub OAuth. # Need to get client ID and client secret from GitHub --> User Settings --> Developer Settings --> OAuth Apps # also need to pip install oauthenticator from oauthenticator.github import LocalGitHubOAuthenticator c.JupyterHub.authenticator_class = LocalGitHubOAuthenticator # Set up config c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # GitHub OAuth Login c.LocalGitHubOAuthenticator.oauth_callback_url = 'https://mydomain.org/hub/oauth_callback' c.LocalGitHubOAuthenticator.client_id = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXX' c.LocalGitHubOAuthenticator.client_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX' c.LocalGitHubOAuthenticator.create_system_users = True #c.Authenticator.whitelist = {'peter','username1','username2'} c.Authenticator.admin_users = {'peter'}","title":"Modify jupyterhub_config.py to use GitHub OAuth"},{"location":"github_oauth/#restart-jupyterhub-and-login-with-github","text":"Restart JupyterHub with: $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Browse over to our server's URL. We see [Sign in with GitHub] in the middle of the page. Log into JupyterHub with a GitHub username and password. After we log in using a GitHub username and password, we can see if JupyterHub created a new user (with our GitHub username) on the server. The command below produces a long list of users. The long list of users contains the non-root sudo user peter and the GitHub user. $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter githubusername We can also verify the GitHub user logged in by going to the /home/ directory on the server. Inside of /home/ should be a home directory for the GitHub user. Inside the GitHub user's directory are any notebooks we just created after we logged in with our GitHub credentials. $ cd /home $ ls peter githubusername $ cd githubusername $ ls Untitled.ipynb","title":"Restart JupyterHub and login with GitHub"},{"location":"github_oauth/#summary","text":"This page documented how to use GitHub usernames and passwords to authenticate with JupyterHub.","title":"Summary"},{"location":"google_oauth/","text":"Google Authentication Now that we have JupyterHub running as a system service and we can log onto JupyterHub with the local PAM authenticator (regular Linux usernames and passwords), we are going to get into the weeds of getting the Google authenticator to work. Google Authentication Why Google OAuth? Google OAuth Instance Pull out the client ID and client secret from the downloaded json file Add the json file to .gitignore Move the json file to the server Install the OAuthenticator package on the server Modify jupyterhub_config.py Restart JupyterHub and Login Summary Next Steps Why Google OAuth? Why Google authenticator instead of local PAM authentication? Our college uses the Gmail suite for both staff and students. When students log onto their college email, they are logging into Gmail. Students can use Google Calendar and Google Drive with their college email account as well. So it would be convenient for students log into JuypterHub using the same Google login they use to access their college email, Google Drive and Calendar. It's just going to take a bit of work to get there. Google OAuth Instance To allow students to use Google usernames and passwords to log into JupyterHub, the first thing we need to do is set up a Google OAuth instance. I set up a Google OAuth instance using my personal Gmail account, rather than my college Gmail account. Some parts of the Google Apps Suite are not available in my college profile, like YouTube and developer tabs. To obtain the Google OAuth credentials, log into the Google API console https://console.developers.google.com/ and select [Credentials] on the lefthand menu. Next, we'll create a new OAuth credential under [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID]: Create a set of Google OAuth credentials using the following input: Authorized JavaScript origins: https://mydomain.org Authorized redirect URIs: https://mydomain.org/hub/oauth_callback After creating a new set of Google OAuth credentials, note the: client ID client secret The client ID and client secret strings will be included in our revised JupyterHub configuration. Note In a previous JupyterHub deployment, I had trouble creating OAuth credentials in Google's developer console. The description of the problem and the solution is below. Note that in this deploymnet of JupyterHub, I am re-using a domain name, so this specific problem didn't crop up. After clicking [Create] a problem surfaced. The Google OAuth dashboard noted that: Invalid Origin: domain must be added to the authorized domains list before submitting Click the [authorized domains list] link and enter the domain name for the JupyterHub server in the text box under [Authorized domains]. Then click [Submit for verification] and [Save]. For some reason the authorize domains submit for verification step and save step took a couple tries and more than a couple minutes. I don't know if Google is doing a DNS lookup or what kind of verification steps they do - either way it took some time for the domain to be \"verified\". Once the domain is verified, go back to the [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID] screen and try entering in the [Authorized JavaScript origins] and [Authorized redirect URIs] again. The scary red [Invalid Origin] should be absent as long as the domain has been verified. Pull out the client ID and client secret from the downloaded json file For this JupyterHub deployment, I also downloaded the .json file that contains the client ID and client secret from Google's OAuth dashboard. You can access the .json file containing the client ID and client secret by clicking the [Credentials] tab and find the credential you just created. On the right hand side is a download icon. Clicking this icon downloads the .json file that contains our client ID and client secret. After the .json file downloads, you can open the .json file in a web browser or a code editor. It has a structure that looks like this: { \"web\": { \"client_id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX.apps.googleusercontent.com\", \"project_id\": \"intense-agency-89620\", \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\", \"token_uri\": \"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\", \"client_secret\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"redirect_uris\": [ \"https://mydomain.org/hub/oauth_callback\" ] } } On a local computer, rename the json file to google_oauth_credentials.json . We can use Python and the json module from the Standard Library to pull out the \"client_id\" and \"client_secret\" from the json file. Make sure the json file is in the same directory on your local computer where the Python code is run. Try the following Python code on your local computer: with open('google_oauth_credentials.json') as f: google_oauth = json.load(f) print(google_oauth['web']['client_id']) print(google_oauth['web']['client_secret'] The output will be the 'client_id' and 'client_secret' from the json file. Add the json file to .gitignore Now we need to move the google_oauth_credentials.json to the sever, but before we do: MAKE SURE TO ADD THE FILE TO .gitignore !!! WE DON'T WANT PRIVATE CREDENTIALS STORED ON GITHUB !!! . Warning Important! Do not save private credentials in a public GitHub repository! Keep your credentials private! In .gitignore on my local machine, I added the following lines at the end. Note that locally this file is saved at projectroot/etc/jupyterhub/google_oauth_credentials.json # .gitignore ... ## Config files /etc/jupyterhub/college_id.json /etc/jupyterhub/google_oauth_credentials.json ... Move the json file to the server Now move the .json file over to the server and save it in the /etc/jupyterhub/ directory. I used FileZilla to move the json file over to the server instead of using copy-paste into PuTTY and the nano code editor. Open FileZilla and select [File] \u2192 [Site Manager... ]. Enter in the server's IP address and select the SSH key used to log into the server. Make sure to select: [Protocol:] SFTP - SSH File Transfer Protocol [Host:] IP address of server [Port]: 22 [Logon Type:] Key file [User:] peter (or your non-root sudo user on the server) [Key file:] [Browse...] and find the SSH key used to log onto the server Click [Connect] to connect to the server with FileZilla. Move both file browsers to /etc/jupyterhub . On the local computer, the .json file is present. On the server, only the jupyterhub_config.py file is present. Drag the .json file over to the server side of the window. Now that the .json file is saved on the server, you can close the FileZilla window. After the .json file is saved on the server, the contents of /etc/jupyterhub on the server should be: /etc/jupyterhub/ \u251c\u2500\u2500 google_oauth_credentials.json \u2514\u2500\u2500 jupyterhub_config.py Let's also build a college_id.json file that contains our college domain and college name. We can pull these strings out with Python's json module too. The college_id.json file has the format below: { \"domain\": \"mycollege.edu\", \"name\": \"My College Name\" } We can pull out the \"domain\" and \"name\" from college_id.json with the following Python code: with open('/etc/jupyterhub/college_id.json') as f: college_id = json.load(f) c.LocalGoogleOAuthenticator.hosted_domain = college_id['domain'] c.LocalGoogleOAuthenticator.login_service = college_id['name'] Move the college_id.json file onto the server with FileZilla. After the files are moved over, you should be able to see a couple files in the /etc/jupyterhub directory on the server. $ cd /etc/jupyterhub $ ls college_id.json jupyterhub.sqlite google_oauth_credentials.json jupyterhub_config.py Install the OAuthenticator package on the server Before our JupyterHub server can use Google authentication, we first need to install the OAuthenticator Python package on the server. $ sudo apt-get update $ sudo apt-get upgrade $ conda activate jupyterhubenv (jupyterhubenv)$ pip install oauthenticator Modify jupyterhub_config.py Once we get our Google OAuth credentials uploaded onto the server, and we have installed the oauthenticator package, we need to edit jupyterhub_conf.py again. Note how the google_oauth_credentials.json and college_id.json files are used in the configuration and how the json module is imported at the top. # /etc/jupyterhub/jupyterhub_config.py # used to read the json google oauth config file import json # For Google OAuth from oauthenticator.google import LocalGoogleOAuthenticator # $ pip install oauthenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Google OAuth Login c.JupyterHub.authenticator_class = LocalGoogleOAuthenticator with open('/etc/jupyterhub/google_oauth_credentials.json') as f: google_oauth = json.load(f) c.LocalGoogleOAuthenticator.client_id = google_oauth['web']['client_id'] c.LocalGoogleOAuthenticator.client_secret = google_oauth['web']['client_secret'] c.LocalGoogleOAuthenticator.oauth_callback_url = google_oauth[\"web\"][\"redirect_uris\"][0] c.LocalGoogleOAuthenticator.create_system_users = True c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] with open('/etc/jupyterhub/college_id.json') as f: college_id = json.load(f) c.LocalGoogleOAuthenticator.hosted_domain = [college_id['domain']] # replace with mycollege.edu, must be a list of strings c.LocalGoogleOAuthenticator.login_service = college_id['name'] # replace with 'My College Name' ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True ## Users c.Authenticator.admin_users = {'peter','peter.kazarinoff'} This little line: c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] was a real gottacha! Our college email addresses are in the form: firstname.lastname@college.edu When a student logs in, JupyterHub tries to create a new Linux user with a dot . in their username. Usernames with . doesn't work on Linux. I tried to create a new Linux user with a dot in their username, and the terminal asked me to use the --force-badname flag. So --force-badname is what we'll add to the c.Authenticator.add_user_cmd list. Otherwise, users (students) will be able to authenticate with Google, but they won't get a new user account on the server, and they won't be able to run notebooks or Python code. Restart JupyterHub and Login Restart JupyterHub and browse to the web address attached to the server. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl + c] to exit \u25cf jupyterhub.service - JupyterHub Loaded: loaded (/etc/systemd/system/jupyterhub.service; disabled; vendor preset: enabled) Active: active (running) since Fri 2019-02-08 18:42:23 UTC; 6s ago Main PID: 9178 (jupyterhub) Tasks: 8 (limit: 1152) If JupyterHub is running OK and there were no errors after the revisions to the jupyterhub_config.py file, open a web browser and try to Log in. The login window should now look something like: We can log in with our Google user name and password (college username and password). Pretty sweet! Note the Jupyter notebook file browser is empty after we log on. A new user was created by JupyterHub when we logged in. This new user's home directory is empty. If you added your college username was added to the c.Authenticator.admin_users = { } set in jupyterhub_config.py , you will be able to see an [Admin] tab when you click [Control Panel] in the Jupyter notebook file browser. If you click [Admin], you should see three users in the user list. In the admin screen, you can shut down the individual notebook servers and logout. After we log in using our college username and password, we can see if JupyterHub created a new user (with our college username) on the server. The command below produces a long list of users. This long list contains the non-root sudo user peter and the Google authenticated user (college username). $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter gabby peter.kazarinoff Summary This was a big section and we got a lot accomplished. At the end of it, we have a running JupyterHub server that allows students and faculty to log into JupyterHub using their college useranmes and passwords. We accomplished this in a couple steps: Create a Google OAuth instance in the Google Developer's console. Download and save the .json file that stores the client ID and client secret. Figure out how to pull the client ID and secret out of the .json file using Python's json module from the Python Standard Library. Add the .json file to .gitignore so that our private client ID and private client secret are not made public. Move the .json file over to the server with FileZilla. Create a college_id.json file and move it over to the server with FileZilla. Modify the jupyterhub_config.py file. Add Google authentication to our JupyterHub configuration. On the server, pip install oauthenticator into the virtual environment that runs JupyterHub. Restart JupyterHub and login with a Google username and password. Use the JuputerHub admin and the terminal to see the new user JupyterHub created. Next Steps The next step is to make the login screen look like our college login screen. Right now, students see a orange button on the login screen. Next, we'll mess around with some templates, html and css to get our JupyterHub login screen to look a lot more like our college login screen.","title":"Google OAuth"},{"location":"google_oauth/#google-authentication","text":"Now that we have JupyterHub running as a system service and we can log onto JupyterHub with the local PAM authenticator (regular Linux usernames and passwords), we are going to get into the weeds of getting the Google authenticator to work. Google Authentication Why Google OAuth? Google OAuth Instance Pull out the client ID and client secret from the downloaded json file Add the json file to .gitignore Move the json file to the server Install the OAuthenticator package on the server Modify jupyterhub_config.py Restart JupyterHub and Login Summary Next Steps","title":"Google Authentication"},{"location":"google_oauth/#why-google-oauth","text":"Why Google authenticator instead of local PAM authentication? Our college uses the Gmail suite for both staff and students. When students log onto their college email, they are logging into Gmail. Students can use Google Calendar and Google Drive with their college email account as well. So it would be convenient for students log into JuypterHub using the same Google login they use to access their college email, Google Drive and Calendar. It's just going to take a bit of work to get there.","title":"Why Google OAuth?"},{"location":"google_oauth/#google-oauth-instance","text":"To allow students to use Google usernames and passwords to log into JupyterHub, the first thing we need to do is set up a Google OAuth instance. I set up a Google OAuth instance using my personal Gmail account, rather than my college Gmail account. Some parts of the Google Apps Suite are not available in my college profile, like YouTube and developer tabs. To obtain the Google OAuth credentials, log into the Google API console https://console.developers.google.com/ and select [Credentials] on the lefthand menu. Next, we'll create a new OAuth credential under [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID]: Create a set of Google OAuth credentials using the following input: Authorized JavaScript origins: https://mydomain.org Authorized redirect URIs: https://mydomain.org/hub/oauth_callback After creating a new set of Google OAuth credentials, note the: client ID client secret The client ID and client secret strings will be included in our revised JupyterHub configuration. Note In a previous JupyterHub deployment, I had trouble creating OAuth credentials in Google's developer console. The description of the problem and the solution is below. Note that in this deploymnet of JupyterHub, I am re-using a domain name, so this specific problem didn't crop up. After clicking [Create] a problem surfaced. The Google OAuth dashboard noted that: Invalid Origin: domain must be added to the authorized domains list before submitting Click the [authorized domains list] link and enter the domain name for the JupyterHub server in the text box under [Authorized domains]. Then click [Submit for verification] and [Save]. For some reason the authorize domains submit for verification step and save step took a couple tries and more than a couple minutes. I don't know if Google is doing a DNS lookup or what kind of verification steps they do - either way it took some time for the domain to be \"verified\". Once the domain is verified, go back to the [Credentials] \u2192 [Create Credentials] \u2192 [OAuth client ID] screen and try entering in the [Authorized JavaScript origins] and [Authorized redirect URIs] again. The scary red [Invalid Origin] should be absent as long as the domain has been verified.","title":"Google OAuth Instance"},{"location":"google_oauth/#pull-out-the-client-id-and-client-secret-from-the-downloaded-json-file","text":"For this JupyterHub deployment, I also downloaded the .json file that contains the client ID and client secret from Google's OAuth dashboard. You can access the .json file containing the client ID and client secret by clicking the [Credentials] tab and find the credential you just created. On the right hand side is a download icon. Clicking this icon downloads the .json file that contains our client ID and client secret. After the .json file downloads, you can open the .json file in a web browser or a code editor. It has a structure that looks like this: { \"web\": { \"client_id\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX.apps.googleusercontent.com\", \"project_id\": \"intense-agency-89620\", \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\", \"token_uri\": \"https://oauth2.googleapis.com/token\", \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\", \"client_secret\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"redirect_uris\": [ \"https://mydomain.org/hub/oauth_callback\" ] } } On a local computer, rename the json file to google_oauth_credentials.json . We can use Python and the json module from the Standard Library to pull out the \"client_id\" and \"client_secret\" from the json file. Make sure the json file is in the same directory on your local computer where the Python code is run. Try the following Python code on your local computer: with open('google_oauth_credentials.json') as f: google_oauth = json.load(f) print(google_oauth['web']['client_id']) print(google_oauth['web']['client_secret'] The output will be the 'client_id' and 'client_secret' from the json file.","title":"Pull out the client ID and client secret from the downloaded json file"},{"location":"google_oauth/#add-the-json-file-to-gitignore","text":"Now we need to move the google_oauth_credentials.json to the sever, but before we do: MAKE SURE TO ADD THE FILE TO .gitignore !!! WE DON'T WANT PRIVATE CREDENTIALS STORED ON GITHUB !!! . Warning Important! Do not save private credentials in a public GitHub repository! Keep your credentials private! In .gitignore on my local machine, I added the following lines at the end. Note that locally this file is saved at projectroot/etc/jupyterhub/google_oauth_credentials.json # .gitignore ... ## Config files /etc/jupyterhub/college_id.json /etc/jupyterhub/google_oauth_credentials.json ...","title":"Add the json file to .gitignore"},{"location":"google_oauth/#move-the-json-file-to-the-server","text":"Now move the .json file over to the server and save it in the /etc/jupyterhub/ directory. I used FileZilla to move the json file over to the server instead of using copy-paste into PuTTY and the nano code editor. Open FileZilla and select [File] \u2192 [Site Manager... ]. Enter in the server's IP address and select the SSH key used to log into the server. Make sure to select: [Protocol:] SFTP - SSH File Transfer Protocol [Host:] IP address of server [Port]: 22 [Logon Type:] Key file [User:] peter (or your non-root sudo user on the server) [Key file:] [Browse...] and find the SSH key used to log onto the server Click [Connect] to connect to the server with FileZilla. Move both file browsers to /etc/jupyterhub . On the local computer, the .json file is present. On the server, only the jupyterhub_config.py file is present. Drag the .json file over to the server side of the window. Now that the .json file is saved on the server, you can close the FileZilla window. After the .json file is saved on the server, the contents of /etc/jupyterhub on the server should be: /etc/jupyterhub/ \u251c\u2500\u2500 google_oauth_credentials.json \u2514\u2500\u2500 jupyterhub_config.py Let's also build a college_id.json file that contains our college domain and college name. We can pull these strings out with Python's json module too. The college_id.json file has the format below: { \"domain\": \"mycollege.edu\", \"name\": \"My College Name\" } We can pull out the \"domain\" and \"name\" from college_id.json with the following Python code: with open('/etc/jupyterhub/college_id.json') as f: college_id = json.load(f) c.LocalGoogleOAuthenticator.hosted_domain = college_id['domain'] c.LocalGoogleOAuthenticator.login_service = college_id['name'] Move the college_id.json file onto the server with FileZilla. After the files are moved over, you should be able to see a couple files in the /etc/jupyterhub directory on the server. $ cd /etc/jupyterhub $ ls college_id.json jupyterhub.sqlite google_oauth_credentials.json jupyterhub_config.py","title":"Move the json file to the server"},{"location":"google_oauth/#install-the-oauthenticator-package-on-the-server","text":"Before our JupyterHub server can use Google authentication, we first need to install the OAuthenticator Python package on the server. $ sudo apt-get update $ sudo apt-get upgrade $ conda activate jupyterhubenv (jupyterhubenv)$ pip install oauthenticator","title":"Install the OAuthenticator package on the server"},{"location":"google_oauth/#modify-jupyterhub_configpy","text":"Once we get our Google OAuth credentials uploaded onto the server, and we have installed the oauthenticator package, we need to edit jupyterhub_conf.py again. Note how the google_oauth_credentials.json and college_id.json files are used in the configuration and how the json module is imported at the top. # /etc/jupyterhub/jupyterhub_config.py # used to read the json google oauth config file import json # For Google OAuth from oauthenticator.google import LocalGoogleOAuthenticator # $ pip install oauthenticator c = get_config() c.JupyterHub.log_level = 10 c.Spawner.cmd = '/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub-singleuser' # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' # Google OAuth Login c.JupyterHub.authenticator_class = LocalGoogleOAuthenticator with open('/etc/jupyterhub/google_oauth_credentials.json') as f: google_oauth = json.load(f) c.LocalGoogleOAuthenticator.client_id = google_oauth['web']['client_id'] c.LocalGoogleOAuthenticator.client_secret = google_oauth['web']['client_secret'] c.LocalGoogleOAuthenticator.oauth_callback_url = google_oauth[\"web\"][\"redirect_uris\"][0] c.LocalGoogleOAuthenticator.create_system_users = True c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] with open('/etc/jupyterhub/college_id.json') as f: college_id = json.load(f) c.LocalGoogleOAuthenticator.hosted_domain = [college_id['domain']] # replace with mycollege.edu, must be a list of strings c.LocalGoogleOAuthenticator.login_service = college_id['name'] # replace with 'My College Name' ## Extra Configuration # Maximum number of concurrent servers that can be active at a time c.JupyterHub.active_server_limit = 26 # Maximum number of concurrent users that can be spawning at a time c.JupyterHub.concurrent_spawn_limit = 13 # Whether to shutdown the proxy when the Hub shuts down. c.JupyterHub.cleanup_proxy = True # Whether to shutdown single-user servers when the Hub shuts down. c.JupyterHub.cleanup_servers = True ## Users c.Authenticator.admin_users = {'peter','peter.kazarinoff'} This little line: c.Authenticator.add_user_cmd = ['adduser', '-q', '--gecos', '\"\"', '--disabled-password', '--force-badname'] was a real gottacha! Our college email addresses are in the form: firstname.lastname@college.edu When a student logs in, JupyterHub tries to create a new Linux user with a dot . in their username. Usernames with . doesn't work on Linux. I tried to create a new Linux user with a dot in their username, and the terminal asked me to use the --force-badname flag. So --force-badname is what we'll add to the c.Authenticator.add_user_cmd list. Otherwise, users (students) will be able to authenticate with Google, but they won't get a new user account on the server, and they won't be able to run notebooks or Python code.","title":"Modify jupyterhub_config.py"},{"location":"google_oauth/#restart-jupyterhub-and-login","text":"Restart JupyterHub and browse to the web address attached to the server. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl + c] to exit \u25cf jupyterhub.service - JupyterHub Loaded: loaded (/etc/systemd/system/jupyterhub.service; disabled; vendor preset: enabled) Active: active (running) since Fri 2019-02-08 18:42:23 UTC; 6s ago Main PID: 9178 (jupyterhub) Tasks: 8 (limit: 1152) If JupyterHub is running OK and there were no errors after the revisions to the jupyterhub_config.py file, open a web browser and try to Log in. The login window should now look something like: We can log in with our Google user name and password (college username and password). Pretty sweet! Note the Jupyter notebook file browser is empty after we log on. A new user was created by JupyterHub when we logged in. This new user's home directory is empty. If you added your college username was added to the c.Authenticator.admin_users = { } set in jupyterhub_config.py , you will be able to see an [Admin] tab when you click [Control Panel] in the Jupyter notebook file browser. If you click [Admin], you should see three users in the user list. In the admin screen, you can shut down the individual notebook servers and logout. After we log in using our college username and password, we can see if JupyterHub created a new user (with our college username) on the server. The command below produces a long list of users. This long list contains the non-root sudo user peter and the Google authenticated user (college username). $ awk -F':' '{ print $1}' /etc/passwd .... uuidd dnsmasq landscape sshd pollinate peter gabby peter.kazarinoff","title":"Restart JupyterHub and Login"},{"location":"google_oauth/#summary","text":"This was a big section and we got a lot accomplished. At the end of it, we have a running JupyterHub server that allows students and faculty to log into JupyterHub using their college useranmes and passwords. We accomplished this in a couple steps: Create a Google OAuth instance in the Google Developer's console. Download and save the .json file that stores the client ID and client secret. Figure out how to pull the client ID and secret out of the .json file using Python's json module from the Python Standard Library. Add the .json file to .gitignore so that our private client ID and private client secret are not made public. Move the .json file over to the server with FileZilla. Create a college_id.json file and move it over to the server with FileZilla. Modify the jupyterhub_config.py file. Add Google authentication to our JupyterHub configuration. On the server, pip install oauthenticator into the virtual environment that runs JupyterHub. Restart JupyterHub and login with a Google username and password. Use the JuputerHub admin and the terminal to see the new user JupyterHub created.","title":"Summary"},{"location":"google_oauth/#next-steps","text":"The next step is to make the login screen look like our college login screen. Right now, students see a orange button on the login screen. Next, we'll mess around with some templates, html and css to get our JupyterHub login screen to look a lot more like our college login screen.","title":"Next Steps"},{"location":"install_jupyterhub/","text":"Install JupyterHub After the server is set up, it is time to install JupyterHub. Install JupyterHub Update System Install Miniconda Change Miniconda3 Permissions Create a virtual environment and install and packages Run a very unsecured instance of Jupyter Hub just to see if it works Quick! Log out and shut down JupyterHub Next Steps Update System It is probably best to update the packages installed on the server in case there are changes and updates to the operating system since the server was created. sudo apt-get update is probably a reflex for those that use Linux a lot. Open PuTTY and log into the server as the non-root sudo user we created in the last step. Then update the system: $ sudo apt-get update $ sudo apt-get upgrade Install Miniconda Next we'll install Miniconda . In the last JupyterHub deployment, I installed the full version of Anaconda in the non-root user's home directory( /home/peter/ ). The user's home directory is the default Anaconda3 installation location. However, for this JupyterHub deployment, we'll install Miniconda in the /opt directory. The Miniconda install is lighter than the full Anaconda install, and we don't need all the GUI applications that Anaconda provides. The packages that we need in this deployment of JupyterHub, we can install in a seperate virtual environment. I followed this tutorial from Digital Ocean. Go to https://repo.continuum.io/archive/ and look down the list of installs for the newest installer that corresponds to: Miniconda3 (not Miniconda2, we don't want legacy Python version 2.7) Linux x86 64 (bit) .sh (linux shell script) The URL of the latest Miniconda install for Linux will look something like: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh To downland and install Miniconda on the server, we'll use the curl command and run the bash installer from the command line: $ cd /tmp $ curl -O https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh $ sudo bash Miniconda3-latest-Linux-x86_64.sh During the Miniconda install, we need to specify the following installation directory: /opt/miniconda3/ When the Miniconda install finished, the installer asked Do you wish the installer to initialize Miniconda3 by running conda init? [yes|no] I selected yes to run conda init. We want to be able to run conda from the command line. So make sure to allow Miniconda to append your PATH during the installation. After installation, we need to reload the .bashrc file because Miniconda made changes to our .bashrc during the install (when it added conda to our PATH). $ cd ~ $ source .bashrc When the install is complete, look in /opt , and see the miniconda3 directory. $ cd /opt $ ls miniconda3 Change Miniconda3 Permissions Now we need to deal with some permission issues. Since I am running as the user peter on the Digital Ocean server, I need to make sure that the user peter has read, write, and execute permissions on the enitre /opt/miniconda3/ directory. We can give our peter user permissions with chmod and chown . $ cd /opt $ ls miniconda3 $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxr-xr-x 13 root root 4096 Oct 30 04:47 miniconda3 Currently, the owner of the miniconda3 directory is root and the group is root . The owner root has read, write, execute privaleges ( rwx ) and the group root has read, execute privaleges ( r-x ), but no write prvialeges. Let's modify the read, write, execute privaleges of the minconda3/ directory so that the group root can read, write, and execute ( rwx ). $ sudo chmod -R g+w miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root root 4096 Oct 30 04:47 miniconda3 OK, now let's change the group corresponding to the miniconda3/ directory from root to peter . $ sudo chown -R root:peter miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root peter 4096 Oct 30 04:47 miniconda3 Now the user peter will be able to install packages using conda and pip in the miniconda3 installation in the /opt directory. Now that the permissions are changed, we should be able to run conda from the command line. Try: $ conda --version If you see output, that means Miniconda was installed and conda can be run by the non-root user. Create a virtual environment and install and packages For this JupyterHub install, we are going to create a conda environment (a virtual environment) and install packages into that environment. I had trouble with conda hanging during the JupterHub installation, and I wondered if it had something to do with the Anaconda installation being so large. (Really, now I think it might also have something to do with Python version 3.7). In a previous JupyterHub installation, when I tried to make a Python 3.7 conda environment and install JupyterHub into it, conda downgraded Python from 3.7 to 3.6. In Fall 2019, I am pretty sure that JupyterHub runs on Python 3.7, but I still had trouble installing conda packages into the conda environment I created based on Python 3.7. When I tried to install conda packages into the environment I recieved \"can't access such and such file at .gobledegook\". But when I closed the terminal, took a 5 hour break, and opened up a new terminal, I could install conda packages just fine. Maybe just logging in and out worked? I'm not really sure. But the conda environment was created with Python 3.7 and now I can install packages into it, so I'll count that as a win. Maybe logging out and back in does the trick. Note: Don't forget to install xlrd , this package is needed for pandas to read .xlsx files. $ conda create -n jupyerhubenv python=3.7 $ conda activate jupyterhubenv (jupyterhubenv)$ conda install numpy matplotlib pandas scipy sympy seaborn bokeh holoviews pyserial xlrd jupyter notebook (jupyterhubenv)$ conda install -c conda-forge pint altair (jupyterhubenv)$ conda install -c conda-forge jupyterlab (jupyterhubenv)$ conda install -c conda-forge jupyterhub Now try conda list and see all of the packages that are installed in (jupyterhubenv) . (jupyterhubenv)$ conda list # packages in environment at /opt/miniconda3/envs/jupyterhubenv: # # Name Version Build Channel _libgcc_mutex 0.1 main alembic 1.0.11 py_0 conda-forge altair 3.2.0 py37_0 conda-forge ... Run a very unsecured instance of Jupyter Hub just to see if it works So... This might not be a good idea, but let's see if JupyterHub works. We can run JupyterHub on our server, but the ufw firewall is blocking port 8000. We can open port 8000 using the command below. $ sudo ufw allow 8000 $ sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) ALLOW Anywhere (v6) OK let's give JupyterHub a whirl. We'll start JupterHub for the first time. Note the --no-ssl flag at the end of the command. This flag needs to be included or you won't be able to browse to the server. Also note we have to be our (jupyterhubenv) virtual environment active when we run the command. $(jupyterhubenv) jupyterhub --no-ssl We see some output in the PuTTY window. The last line is something like JupyterHub is now running at http://:8000/ . The first time I set up JupyterHub, I wasn't able to see the site using a web browser. No web page loaded, and the connection timed out. Opening port 8000 did the trick. Now we can browse to the server IP address of our Digital Ocean Droplet appended with :8000 . The web address should look something like: http://165.228.68.178:8000. You can find the IP address of the server by going into the Digital Ocean dashboard. The JupyterHub login screen looks like: Awesome! Quick log into JupyterHub using the username and password for the non-root sudo user (in my case peter ) that we set up and are using in our current PuTTY session. You should see the typical notebook file browser with all the files you can see when you run ls ~/ . Try creating and running a new Jupyter notebook. The notebook works just like a Jupyter notebook running locally . Quick! Log out and shut down JupyterHub Warning Warning! You should not run JupyterHub without SSL encryption on a public network. Quick! Log out and shut down JupyterHub . (does quick really matter in internet security?) The site is running without any ssl security over regular HTTP not HTTPS. Key in [Ctrl] + [c] to stop JupyterHub. After I shut the JupyterHub instance down, I re-blocked port 8000 with the command below. $ sudo ufw deny 8000 $ sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 DENY Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) DENY Anywhere (v6) Next Steps The next step is to aquire a domain name and link it to our Digital Ocean server.","title":"Install JupyterHub"},{"location":"install_jupyterhub/#install-jupyterhub","text":"After the server is set up, it is time to install JupyterHub. Install JupyterHub Update System Install Miniconda Change Miniconda3 Permissions Create a virtual environment and install and packages Run a very unsecured instance of Jupyter Hub just to see if it works Quick! Log out and shut down JupyterHub Next Steps","title":"Install JupyterHub"},{"location":"install_jupyterhub/#update-system","text":"It is probably best to update the packages installed on the server in case there are changes and updates to the operating system since the server was created. sudo apt-get update is probably a reflex for those that use Linux a lot. Open PuTTY and log into the server as the non-root sudo user we created in the last step. Then update the system: $ sudo apt-get update $ sudo apt-get upgrade","title":"Update System"},{"location":"install_jupyterhub/#install-miniconda","text":"Next we'll install Miniconda . In the last JupyterHub deployment, I installed the full version of Anaconda in the non-root user's home directory( /home/peter/ ). The user's home directory is the default Anaconda3 installation location. However, for this JupyterHub deployment, we'll install Miniconda in the /opt directory. The Miniconda install is lighter than the full Anaconda install, and we don't need all the GUI applications that Anaconda provides. The packages that we need in this deployment of JupyterHub, we can install in a seperate virtual environment. I followed this tutorial from Digital Ocean. Go to https://repo.continuum.io/archive/ and look down the list of installs for the newest installer that corresponds to: Miniconda3 (not Miniconda2, we don't want legacy Python version 2.7) Linux x86 64 (bit) .sh (linux shell script) The URL of the latest Miniconda install for Linux will look something like: https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh To downland and install Miniconda on the server, we'll use the curl command and run the bash installer from the command line: $ cd /tmp $ curl -O https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh $ sudo bash Miniconda3-latest-Linux-x86_64.sh During the Miniconda install, we need to specify the following installation directory: /opt/miniconda3/ When the Miniconda install finished, the installer asked Do you wish the installer to initialize Miniconda3 by running conda init? [yes|no] I selected yes to run conda init. We want to be able to run conda from the command line. So make sure to allow Miniconda to append your PATH during the installation. After installation, we need to reload the .bashrc file because Miniconda made changes to our .bashrc during the install (when it added conda to our PATH). $ cd ~ $ source .bashrc When the install is complete, look in /opt , and see the miniconda3 directory. $ cd /opt $ ls miniconda3","title":"Install Miniconda"},{"location":"install_jupyterhub/#change-miniconda3-permissions","text":"Now we need to deal with some permission issues. Since I am running as the user peter on the Digital Ocean server, I need to make sure that the user peter has read, write, and execute permissions on the enitre /opt/miniconda3/ directory. We can give our peter user permissions with chmod and chown . $ cd /opt $ ls miniconda3 $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxr-xr-x 13 root root 4096 Oct 30 04:47 miniconda3 Currently, the owner of the miniconda3 directory is root and the group is root . The owner root has read, write, execute privaleges ( rwx ) and the group root has read, execute privaleges ( r-x ), but no write prvialeges. Let's modify the read, write, execute privaleges of the minconda3/ directory so that the group root can read, write, and execute ( rwx ). $ sudo chmod -R g+w miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root root 4096 Oct 30 04:47 miniconda3 OK, now let's change the group corresponding to the miniconda3/ directory from root to peter . $ sudo chown -R root:peter miniconda3/ $ ls -la total 12 drwxr-xr-x 3 root root 4096 Oct 30 04:47 . drwxr-xr-x 23 root root 4096 Oct 29 17:49 .. drwxrwxr-x 13 root peter 4096 Oct 30 04:47 miniconda3 Now the user peter will be able to install packages using conda and pip in the miniconda3 installation in the /opt directory. Now that the permissions are changed, we should be able to run conda from the command line. Try: $ conda --version If you see output, that means Miniconda was installed and conda can be run by the non-root user.","title":"Change Miniconda3 Permissions"},{"location":"install_jupyterhub/#create-a-virtual-environment-and-install-and-packages","text":"For this JupyterHub install, we are going to create a conda environment (a virtual environment) and install packages into that environment. I had trouble with conda hanging during the JupterHub installation, and I wondered if it had something to do with the Anaconda installation being so large. (Really, now I think it might also have something to do with Python version 3.7). In a previous JupyterHub installation, when I tried to make a Python 3.7 conda environment and install JupyterHub into it, conda downgraded Python from 3.7 to 3.6. In Fall 2019, I am pretty sure that JupyterHub runs on Python 3.7, but I still had trouble installing conda packages into the conda environment I created based on Python 3.7. When I tried to install conda packages into the environment I recieved \"can't access such and such file at .gobledegook\". But when I closed the terminal, took a 5 hour break, and opened up a new terminal, I could install conda packages just fine. Maybe just logging in and out worked? I'm not really sure. But the conda environment was created with Python 3.7 and now I can install packages into it, so I'll count that as a win. Maybe logging out and back in does the trick. Note: Don't forget to install xlrd , this package is needed for pandas to read .xlsx files. $ conda create -n jupyerhubenv python=3.7 $ conda activate jupyterhubenv (jupyterhubenv)$ conda install numpy matplotlib pandas scipy sympy seaborn bokeh holoviews pyserial xlrd jupyter notebook (jupyterhubenv)$ conda install -c conda-forge pint altair (jupyterhubenv)$ conda install -c conda-forge jupyterlab (jupyterhubenv)$ conda install -c conda-forge jupyterhub Now try conda list and see all of the packages that are installed in (jupyterhubenv) . (jupyterhubenv)$ conda list # packages in environment at /opt/miniconda3/envs/jupyterhubenv: # # Name Version Build Channel _libgcc_mutex 0.1 main alembic 1.0.11 py_0 conda-forge altair 3.2.0 py37_0 conda-forge ...","title":"Create a virtual environment and install and packages"},{"location":"install_jupyterhub/#run-a-very-unsecured-instance-of-jupyter-hub-just-to-see-if-it-works","text":"So... This might not be a good idea, but let's see if JupyterHub works. We can run JupyterHub on our server, but the ufw firewall is blocking port 8000. We can open port 8000 using the command below. $ sudo ufw allow 8000 $ sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) ALLOW Anywhere (v6) OK let's give JupyterHub a whirl. We'll start JupterHub for the first time. Note the --no-ssl flag at the end of the command. This flag needs to be included or you won't be able to browse to the server. Also note we have to be our (jupyterhubenv) virtual environment active when we run the command. $(jupyterhubenv) jupyterhub --no-ssl We see some output in the PuTTY window. The last line is something like JupyterHub is now running at http://:8000/ . The first time I set up JupyterHub, I wasn't able to see the site using a web browser. No web page loaded, and the connection timed out. Opening port 8000 did the trick. Now we can browse to the server IP address of our Digital Ocean Droplet appended with :8000 . The web address should look something like: http://165.228.68.178:8000. You can find the IP address of the server by going into the Digital Ocean dashboard. The JupyterHub login screen looks like: Awesome! Quick log into JupyterHub using the username and password for the non-root sudo user (in my case peter ) that we set up and are using in our current PuTTY session. You should see the typical notebook file browser with all the files you can see when you run ls ~/ . Try creating and running a new Jupyter notebook. The notebook works just like a Jupyter notebook running locally .","title":"Run a very unsecured instance of Jupyter Hub just to see if it works"},{"location":"install_jupyterhub/#quick-log-out-and-shut-down-jupyterhub","text":"Warning Warning! You should not run JupyterHub without SSL encryption on a public network. Quick! Log out and shut down JupyterHub . (does quick really matter in internet security?) The site is running without any ssl security over regular HTTP not HTTPS. Key in [Ctrl] + [c] to stop JupyterHub. After I shut the JupyterHub instance down, I re-blocked port 8000 with the command below. $ sudo ufw deny 8000 $ sudo ufw status Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 DENY Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) DENY Anywhere (v6)","title":"Quick! Log out and shut down JupyterHub"},{"location":"install_jupyterhub/#next-steps","text":"The next step is to aquire a domain name and link it to our Digital Ocean server.","title":"Next Steps"},{"location":"jupyterhub_config/","text":"JupyterHub Configuration Next, we'll create a jupyterhub_config.py file and modify the file to include our cookie secret and proxy auth token. JupyterHub Configuration Create jupyterhub_config.py Modify jupyterhub_config.py Restart nginx and start JupyterHub, see if we can login Create an new user, restart JupyterHub and Login. Next Steps Create jupyterhub_config.py We'll create the JupyterHub config file in the /etc/jupyterhub directory. After the directory is created, we need to modify the directory permissions. Then cd into it create the config file with jupyterhub --generate-config . Make sure you are in the (jupyterhubenv) virtual environment when you run the --generate-config command. $ cd /etc $ sudo mkdir jupyterhub $ sudo chown -R root:peter jupyterhub/ $ sudo chmod -R g+rwx jupyterhub/ $ cd jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ jupyterhub --generate-config Writing default config to: jupyterhub_config.py $ ls jupyterhub_config.py Modify jupyterhub_config.py Now we'll modify the jupyterhub_config.py file to allow local spawners and include our user peter as an admin user: $ nano jupyterhub_config.py There will be a lot of commented out text in the jupyterhub_config.py file. At the top of the file, add the following: # /etc/jupyterhub/jupyterhub_config.py c = get_config() c.JupyterHub.log_level = 10 # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' c.Authenticator.whitelist = {'peter'} c.Authenticator.admin_users = {'peter'} Restart nginx and start JupyterHub, see if we can login Now we'll restart Nginx and start JupyterHub. Not that this time when we start JupyterHub we don't need to use the --no-ssl flag. This is because we have SSL running on Nginx. If it seems like Nginx isn't working, try $ sudo systemctl status nginx and see if nginx really started. If it didn't, try the command nginx -t . This command prints out any error messages if Nginx failed to start. I had to trouble shoot Nginx many a lot before I got Nginx and JupyterHub working together. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [ctrl-c] to exit Once Nginx is running, restart JupyterHub without the --no-ssl flag. Make sure the (jupyterhubenv) virtual environment is active before running the jupyterhub command. $ cd /etc/jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ jupyterhub Log in to JupyterHub with the non-root sudo username ( peter ) and password (same user that's running the PuTTY session). Now we can browse to our domain and see JupyterHub running in its full SSL glory. Create an new user, restart JupyterHub and Login. OK, it's all well and good that we can log in. But the purpose of setting up JupyterHub is for multiple students to be able to log on an run Python code. To test if multiple students can run Python code on JupyterHub at the same time, we need to create another user on the server. If JupyterHub is still running, stop it with [Ctrl] + [c]. Let's create a new user and see if we can log in as her. $ sudo adduser gabby Go through the prompts and remember the UNIX password. Now we'll modify jupyterhub_conf.py to include our new user gabby and add peter (our non-root sudo user) as an administrator: ... c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter'} Restart JupyterHub and try and login as gabby (jupyterhubenv)$ jupyterhub Next Steps The next step is to run JupyterHub as a system service. This allows JupyterHub to run continuously even if we aren't logged into the server. It also allows us to work on our JupyterHub deployment while it is still running.","title":"JupyterHub Configuration"},{"location":"jupyterhub_config/#jupyterhub-configuration","text":"Next, we'll create a jupyterhub_config.py file and modify the file to include our cookie secret and proxy auth token. JupyterHub Configuration Create jupyterhub_config.py Modify jupyterhub_config.py Restart nginx and start JupyterHub, see if we can login Create an new user, restart JupyterHub and Login. Next Steps","title":"JupyterHub Configuration"},{"location":"jupyterhub_config/#create-jupyterhub_configpy","text":"We'll create the JupyterHub config file in the /etc/jupyterhub directory. After the directory is created, we need to modify the directory permissions. Then cd into it create the config file with jupyterhub --generate-config . Make sure you are in the (jupyterhubenv) virtual environment when you run the --generate-config command. $ cd /etc $ sudo mkdir jupyterhub $ sudo chown -R root:peter jupyterhub/ $ sudo chmod -R g+rwx jupyterhub/ $ cd jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ jupyterhub --generate-config Writing default config to: jupyterhub_config.py $ ls jupyterhub_config.py","title":"Create jupyterhub_config.py"},{"location":"jupyterhub_config/#modify-jupyterhub_configpy","text":"Now we'll modify the jupyterhub_config.py file to allow local spawners and include our user peter as an admin user: $ nano jupyterhub_config.py There will be a lot of commented out text in the jupyterhub_config.py file. At the top of the file, add the following: # /etc/jupyterhub/jupyterhub_config.py c = get_config() c.JupyterHub.log_level = 10 # Cookie Secret Files c.JupyterHub.cookie_secret_file = '/srv/jupyterhub/jupyterhub_cookie_secret' c.ConfigurableHTTPProxy.auth_token = '/srv/jupyterhub/proxy_auth_token' c.Authenticator.whitelist = {'peter'} c.Authenticator.admin_users = {'peter'}","title":"Modify jupyterhub_config.py"},{"location":"jupyterhub_config/#restart-nginx-and-start-jupyterhub-see-if-we-can-login","text":"Now we'll restart Nginx and start JupyterHub. Not that this time when we start JupyterHub we don't need to use the --no-ssl flag. This is because we have SSL running on Nginx. If it seems like Nginx isn't working, try $ sudo systemctl status nginx and see if nginx really started. If it didn't, try the command nginx -t . This command prints out any error messages if Nginx failed to start. I had to trouble shoot Nginx many a lot before I got Nginx and JupyterHub working together. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [ctrl-c] to exit Once Nginx is running, restart JupyterHub without the --no-ssl flag. Make sure the (jupyterhubenv) virtual environment is active before running the jupyterhub command. $ cd /etc/jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ jupyterhub Log in to JupyterHub with the non-root sudo username ( peter ) and password (same user that's running the PuTTY session). Now we can browse to our domain and see JupyterHub running in its full SSL glory.","title":"Restart nginx and start JupyterHub, see if we can login"},{"location":"jupyterhub_config/#create-an-new-user-restart-jupyterhub-and-login","text":"OK, it's all well and good that we can log in. But the purpose of setting up JupyterHub is for multiple students to be able to log on an run Python code. To test if multiple students can run Python code on JupyterHub at the same time, we need to create another user on the server. If JupyterHub is still running, stop it with [Ctrl] + [c]. Let's create a new user and see if we can log in as her. $ sudo adduser gabby Go through the prompts and remember the UNIX password. Now we'll modify jupyterhub_conf.py to include our new user gabby and add peter (our non-root sudo user) as an administrator: ... c.Authenticator.whitelist = {'peter','gabby'} c.Authenticator.admin_users = {'peter'} Restart JupyterHub and try and login as gabby (jupyterhubenv)$ jupyterhub","title":"Create an new user, restart JupyterHub and Login."},{"location":"jupyterhub_config/#next-steps","text":"The next step is to run JupyterHub as a system service. This allows JupyterHub to run continuously even if we aren't logged into the server. It also allows us to work on our JupyterHub deployment while it is still running.","title":"Next Steps"},{"location":"jupyterlab_default/","text":"JupyterLab Default Interface Over the summer, when I ran JupterHub for the first time, we used the regular Jupyter notebook interface. For this deployment, I want to prototype using the JupyterLab interface. Below is the file browser in the regular Jupyter notebook interface. This is what students see now when they log into JupyterHub. But students could also be greeted by the JupyterLab interface after they log in. Luckily, the JupyterLab interface is built right into JupyterHub. We can access the JupyterLab interface by logging into JupyerHub and modifying the URL. Below is the URL when you are logged into the notebook file browser: https://mydomain.org/user/user.name/tree In the URL, if we remove /tree and replace it with /lab the result is the JupyterLab interface. https://mydomain.org/user/user.name/lab The resulting JupyterLab interface is shown below: We can get back to the regular notebook interface by replacing /lab with /tree . The regular Jupyter notebook interface, running a notebook, is shown below: If we switch to the JupyterLab interface, the same notebook looks like this: Modify jupyterhub_config.y To use JupyterLab as the default landing page (instead of the regular notebook interface), add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at the JupyterLab Interface c.Spawner.default_url = '/lab' ... That's it. It's that easy to switch between the regular notebook and JupyterLab interfaces. Restart JupyterHub After jupyterhub_config.py is saved, let's restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # ctrl-c to exit the status pannel When we log into JupyterHub, we are greated by the JupyterLab interface: Install JupyterLab extension for JupyterHub Once advantage of the good old classic notebook interface is it contains buttons to login and logout of Jupyter Hub, and buttons to start and stop our server. Login/logout and server start/stop controls are absent from the JupyterLab interface. Luckily, these controls can be added into JupyterLab with the JupyterHub extension for JupyterLab To install the JupyterLab extension for JupyterHub, log into the server, then activate the (jupyterhubenv) virtual environment. The extenion is installed with the command below: $ conda activate jupyterhubenv (jupyterhubenv)$ jupyter labextension install @jupyterlab/hub-extension I had to run this command twice to get the extension to install. Don't know why. The first time I ran the command, I was greeted by an error about installing or using yarn. But when I ran it a second time, it worked. To use JupyterLab extension, add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory: # /etc/jupyterhub/jupyterhub_config.py ... # Use the JupyterLab extension for JupyterHub. # install with $ jupyter labextension install @jupyterlab/hub-extension c.Spawner.cmd = ['jupyter-labhub'] ... Restart JupyterHub After jupyterhub_config.py is saved, restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [ctrl]-[c] to exit the status pannel When we log into JupyterHub, we see the JupyterLab interface with a new [Hub] menu along the top: If you select [Control Pannel], you end up with same buttons contained in the Jupyter notebook interface. If we [Stop My Server], then re-[Start My Server], we end up back in the JupyterLab interface. Next Steps The next step to build a custom login page. When students visit our domain, instead of seeing the regular JupyterHub login page, they see a custom login page that looks a lot like our college login page. This custom login page will look familiar to students.","title":"JupyterLab Default Interface"},{"location":"jupyterlab_default/#jupyterlab-default-interface","text":"Over the summer, when I ran JupterHub for the first time, we used the regular Jupyter notebook interface. For this deployment, I want to prototype using the JupyterLab interface. Below is the file browser in the regular Jupyter notebook interface. This is what students see now when they log into JupyterHub. But students could also be greeted by the JupyterLab interface after they log in. Luckily, the JupyterLab interface is built right into JupyterHub. We can access the JupyterLab interface by logging into JupyerHub and modifying the URL. Below is the URL when you are logged into the notebook file browser: https://mydomain.org/user/user.name/tree In the URL, if we remove /tree and replace it with /lab the result is the JupyterLab interface. https://mydomain.org/user/user.name/lab The resulting JupyterLab interface is shown below: We can get back to the regular notebook interface by replacing /lab with /tree . The regular Jupyter notebook interface, running a notebook, is shown below: If we switch to the JupyterLab interface, the same notebook looks like this:","title":"JupyterLab Default Interface"},{"location":"jupyterlab_default/#modify-jupyterhub_configy","text":"To use JupyterLab as the default landing page (instead of the regular notebook interface), add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at the JupyterLab Interface c.Spawner.default_url = '/lab' ... That's it. It's that easy to switch between the regular notebook and JupyterLab interfaces.","title":"Modify jupyterhub_config.y"},{"location":"jupyterlab_default/#restart-jupyterhub","text":"After jupyterhub_config.py is saved, let's restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # ctrl-c to exit the status pannel When we log into JupyterHub, we are greated by the JupyterLab interface:","title":"Restart JupyterHub"},{"location":"jupyterlab_default/#install-jupyterlab-extension-for-jupyterhub","text":"Once advantage of the good old classic notebook interface is it contains buttons to login and logout of Jupyter Hub, and buttons to start and stop our server. Login/logout and server start/stop controls are absent from the JupyterLab interface. Luckily, these controls can be added into JupyterLab with the JupyterHub extension for JupyterLab To install the JupyterLab extension for JupyterHub, log into the server, then activate the (jupyterhubenv) virtual environment. The extenion is installed with the command below: $ conda activate jupyterhubenv (jupyterhubenv)$ jupyter labextension install @jupyterlab/hub-extension I had to run this command twice to get the extension to install. Don't know why. The first time I ran the command, I was greeted by an error about installing or using yarn. But when I ran it a second time, it worked. To use JupyterLab extension, add a line to jupyterhub_config.py in the /etc/jupyterhub/ directory: # /etc/jupyterhub/jupyterhub_config.py ... # Use the JupyterLab extension for JupyterHub. # install with $ jupyter labextension install @jupyterlab/hub-extension c.Spawner.cmd = ['jupyter-labhub'] ...","title":"Install JupyterLab extension for JupyterHub"},{"location":"jupyterlab_default/#restart-jupyterhub_1","text":"After jupyterhub_config.py is saved, restart JupyterHub and see the results. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [ctrl]-[c] to exit the status pannel When we log into JupyterHub, we see the JupyterLab interface with a new [Hub] menu along the top: If you select [Control Pannel], you end up with same buttons contained in the Jupyter notebook interface. If we [Stop My Server], then re-[Start My Server], we end up back in the JupyterLab interface.","title":"Restart JupyterHub"},{"location":"jupyterlab_default/#next-steps","text":"The next step to build a custom login page. When students visit our domain, instead of seeing the regular JupyterHub login page, they see a custom login page that looks a lot like our college login page. This custom login page will look familiar to students.","title":"Next Steps"},{"location":"login_page/","text":"Custom Login Page The JupyterHub login page looks like this: But our college login page looks like this: For users to feel comfortable with logging into the JupyterHub server, we'll make the JupyterHub login page look more like the college login page. Custom Login Page Create a templates directory and populate it with Jinja templates Modify login.html Modify jupyterhub_config.py Restart JupyterHub and view changes Style the login page with css Restart JupyterHub Next Steps Create a templates directory and populate it with Jinja templates Note This was a time consuming and fussy task. It involved a lot of messing around with css and html. First, a set of custom jinja templates need to be created. When JupyterHub runs, there is a directory of jinja templates that build the html users see when they browse to the login page. These jinga templates are burried deep in the JupyterHub package code. For my JupyterHub installation on the server, I found the jinja template files in the /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub/templates/ directory. If you aren't using a virtual environment, the JupyterHub package directory name will likey be different: /opt/anaconda3/envs/pkgs/jupyterhub/share/jupyterhub/templates/ \u251c\u2500\u2500 404.html \u251c\u2500\u2500 admin.html \u251c\u2500\u2500 error.html \u251c\u2500\u2500 home.html \u251c\u2500\u2500 login.html \u251c\u2500\u2500 logout.html \u251c\u2500\u2500 page.html \u251c\u2500\u2500 spawn.html \u251c\u2500\u2500 spawn_pending.html \u2514\u2500\u2500 token.html Now we need to copy these templates into a new /etc/jupyterhub/templates directory. Once copied, we can modify the templates and create a new JupyterHub login page. login.html is the file we'll customize. $ cd /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub $ ls static templates $ cp -R templates /etc/jupyterhub/templates/ $ cd /etc/jupyterhub/templates $ ls 404.html error.html login.html oauth.html spawn.html stop_pending.html admin.html home.html logout.html page.html spawn_pending.html token.html Modify login.html Open up the login.html file and modify it with any html that you want to show up when a user goes to the JupyterHub site. This is what the user will see first thing, before they have logged in. I messed around for WAY to long trying to get my custom login page to look like the college login page. An important piece of html that needs to stay in the login.html file is the <a> tag that links to the authentication url. The complete tag is detailed below: <!\u2013\u2013 login.html \u2013\u2013> <a role=\"button\" class=\"btn btn-jupyter btn-lg\" href=\"/hub/oauth_login?next=\"> Sign in with Portland Community College </a> I also kept in the jinga tag at the top of the file that brings in all of the formatting from login.html's parent template page.html <!\u2013\u2013 login.html \u2013\u2013> {% extends \"page.html\" %} All the changes I made to the login template were inside the \"login\" block of login.html . {% block login %} <!\u2013\u2013 make changes here \u2013\u2013> {% endblock login %} You can find my complete login.html file on GitHub here . I used the FileZilla SFTP Windows App to move over the login.html . To use FileZilla, Select [File] \u2192 [Site Manager]. Select [SFTP], add the server IP address, username, and select [Log in Type] \u2192 [Key File]. FileZilla settings are below: Modify jupyterhub_config.py Now we need to modify the jupyterhub_config.py file so that our new set of custom jinja templates are used instead of the default jinja templates. Caution A problem I initially had was I set the directory path of the custom templates as templates and the login page didn't work as expected. When I changed the directory path to templates/ the problem was resolved. # /etc/jupyterhub/jupyterhub_config.py ... # sets a custom html template at the login screen. c.JupyterHub.template_paths = ['/etc/jupyterhub/templates/'] ... Restart JupyterHub and view changes With changes to the login.html file complete and the template_paths= set in jupyterhub_config.py , we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit The new login page is below: The login works, but the issue is that without an css, the page looks plain and doesn't really look like the college login page: Therefore, we need to add some css styling to the page. Style the login page with css Finally, the style.min.css file needs to be modified so that the login page styling looks a little more like the college login page. This is another thing I messed around with for a long time, a WAY to long time. I couldn't figure out a way to get JupyterHub to use a custom .css file. I tried creating a .css file in the new custom templates directory, but JupyterHub wouldn't copy it as a static asset when the server launched. I also tried putting a separate .css file deep inside of the JupyterHub package code. When the server ran, it seemed to copy the custom .css file (I could see the custom .css file using chrome's inspect element tool). But for some reason the custom .css file would be blank when server serve was running, even though the custom .css file contained a whole bunch of css code when viewed deep in the JupyterHub package code. The solution I finally got to work was modifying the style.min.css file itself that JupyterHub uses. This file is buried deep in the JupyterHub package code: /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub/static/css \u251c\u2500\u2500 style.min.css \u2514\u2500\u2500 style.min.css.map Modify the style.min.css file to include all the custom css styling desired (find my complete css file on GitHub here ) I used FileZilla again to move over the file. style.min.css is a pretty big file and copying and pasting into PuTTY would probably lead to a lot of errors. Restart JupyterHub With changes to the login.html file and style.min.css file complete, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Below is the look of the modified login page in all it's custom html and css glory: Next Steps The next step is to add Draw.IO to the possible \"apps\" that start in JupyterLab after a student logs into JupyterHub. Draw.IO installed in the JupyterLab interface makes it possible for student to draw flow charts in when they use JupyterHub","title":"Custom Login Page"},{"location":"login_page/#custom-login-page","text":"The JupyterHub login page looks like this: But our college login page looks like this: For users to feel comfortable with logging into the JupyterHub server, we'll make the JupyterHub login page look more like the college login page. Custom Login Page Create a templates directory and populate it with Jinja templates Modify login.html Modify jupyterhub_config.py Restart JupyterHub and view changes Style the login page with css Restart JupyterHub Next Steps","title":"Custom Login Page"},{"location":"login_page/#create-a-templates-directory-and-populate-it-with-jinja-templates","text":"Note This was a time consuming and fussy task. It involved a lot of messing around with css and html. First, a set of custom jinja templates need to be created. When JupyterHub runs, there is a directory of jinja templates that build the html users see when they browse to the login page. These jinga templates are burried deep in the JupyterHub package code. For my JupyterHub installation on the server, I found the jinja template files in the /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub/templates/ directory. If you aren't using a virtual environment, the JupyterHub package directory name will likey be different: /opt/anaconda3/envs/pkgs/jupyterhub/share/jupyterhub/templates/ \u251c\u2500\u2500 404.html \u251c\u2500\u2500 admin.html \u251c\u2500\u2500 error.html \u251c\u2500\u2500 home.html \u251c\u2500\u2500 login.html \u251c\u2500\u2500 logout.html \u251c\u2500\u2500 page.html \u251c\u2500\u2500 spawn.html \u251c\u2500\u2500 spawn_pending.html \u2514\u2500\u2500 token.html Now we need to copy these templates into a new /etc/jupyterhub/templates directory. Once copied, we can modify the templates and create a new JupyterHub login page. login.html is the file we'll customize. $ cd /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub $ ls static templates $ cp -R templates /etc/jupyterhub/templates/ $ cd /etc/jupyterhub/templates $ ls 404.html error.html login.html oauth.html spawn.html stop_pending.html admin.html home.html logout.html page.html spawn_pending.html token.html","title":"Create a templates directory and populate it with Jinja templates"},{"location":"login_page/#modify-loginhtml","text":"Open up the login.html file and modify it with any html that you want to show up when a user goes to the JupyterHub site. This is what the user will see first thing, before they have logged in. I messed around for WAY to long trying to get my custom login page to look like the college login page. An important piece of html that needs to stay in the login.html file is the <a> tag that links to the authentication url. The complete tag is detailed below: <!\u2013\u2013 login.html \u2013\u2013> <a role=\"button\" class=\"btn btn-jupyter btn-lg\" href=\"/hub/oauth_login?next=\"> Sign in with Portland Community College </a> I also kept in the jinga tag at the top of the file that brings in all of the formatting from login.html's parent template page.html <!\u2013\u2013 login.html \u2013\u2013> {% extends \"page.html\" %} All the changes I made to the login template were inside the \"login\" block of login.html . {% block login %} <!\u2013\u2013 make changes here \u2013\u2013> {% endblock login %} You can find my complete login.html file on GitHub here . I used the FileZilla SFTP Windows App to move over the login.html . To use FileZilla, Select [File] \u2192 [Site Manager]. Select [SFTP], add the server IP address, username, and select [Log in Type] \u2192 [Key File]. FileZilla settings are below:","title":"Modify login.html"},{"location":"login_page/#modify-jupyterhub_configpy","text":"Now we need to modify the jupyterhub_config.py file so that our new set of custom jinja templates are used instead of the default jinja templates. Caution A problem I initially had was I set the directory path of the custom templates as templates and the login page didn't work as expected. When I changed the directory path to templates/ the problem was resolved. # /etc/jupyterhub/jupyterhub_config.py ... # sets a custom html template at the login screen. c.JupyterHub.template_paths = ['/etc/jupyterhub/templates/'] ...","title":"Modify jupyterhub_config.py"},{"location":"login_page/#restart-jupyterhub-and-view-changes","text":"With changes to the login.html file complete and the template_paths= set in jupyterhub_config.py , we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit The new login page is below: The login works, but the issue is that without an css, the page looks plain and doesn't really look like the college login page: Therefore, we need to add some css styling to the page.","title":"Restart JupyterHub and view changes"},{"location":"login_page/#style-the-login-page-with-css","text":"Finally, the style.min.css file needs to be modified so that the login page styling looks a little more like the college login page. This is another thing I messed around with for a long time, a WAY to long time. I couldn't figure out a way to get JupyterHub to use a custom .css file. I tried creating a .css file in the new custom templates directory, but JupyterHub wouldn't copy it as a static asset when the server launched. I also tried putting a separate .css file deep inside of the JupyterHub package code. When the server ran, it seemed to copy the custom .css file (I could see the custom .css file using chrome's inspect element tool). But for some reason the custom .css file would be blank when server serve was running, even though the custom .css file contained a whole bunch of css code when viewed deep in the JupyterHub package code. The solution I finally got to work was modifying the style.min.css file itself that JupyterHub uses. This file is buried deep in the JupyterHub package code: /opt/miniconda3/envs/jupyterhubenv/share/jupyterhub/static/css \u251c\u2500\u2500 style.min.css \u2514\u2500\u2500 style.min.css.map Modify the style.min.css file to include all the custom css styling desired (find my complete css file on GitHub here ) I used FileZilla again to move over the file. style.min.css is a pretty big file and copying and pasting into PuTTY would probably lead to a lot of errors.","title":"Style the login page with css"},{"location":"login_page/#restart-jupyterhub","text":"With changes to the login.html file and style.min.css file complete, we can restart JupyterHub and view the changes rendered on the login page. $ sudo systemctl stop jupyterhub $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]-[c] to exit Below is the look of the modified login page in all it's custom html and css glory:","title":"Restart JupyterHub"},{"location":"login_page/#next-steps","text":"The next step is to add Draw.IO to the possible \"apps\" that start in JupyterLab after a student logs into JupyterHub. Draw.IO installed in the JupyterLab interface makes it possible for student to draw flow charts in when they use JupyterHub","title":"Next Steps"},{"location":"nbgitpuller_defaut_url/","text":"nbgitpuller default URL In this section, we will discuss how one might configure the nbgitpuller URL from the previous section into the default URL for our JupyterHub site. This mean that any time a student goes to mydomain.org \u2192 mydomain.org/mycustomgitpullerurl The nbgitpuller plugin pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. When users go to a custom link such as: https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab users end up pulling all the files from the specified GitHub Repo into they JupyterHub folders. They see something like the following in their browser. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub. Add the custom link to jupyterhub_config.py We can add this the nbgitpuller custom link to the jupyterhub_config.py file. We did this before for when we made JupyterLab the default environment . Log into the server and shut down Jupyterhub. $ sudo systemctl stop jupyterhub cd to the /etc/jupyterhub/ directory and open up the jupyterhub_config.py file $ cd /etc/jupyterhub $ ls jupyterhub.sqlite jupyterhub_config.py jupyterhub_cookie_secret templates $ nano jupyterhub_config.py Inside the jupyterhub_config.py file, modify the line c.Spawner.default_url = '/lab' to instead point to the custom nbgitpuller URL. You can build a cusom nbgitpuller URL using this app: https://mybinder.org/v2/gh/jupyterhub/nbgitpuller/master?urlpath=apps/binder%2Flink_generator.ipynb This produces a URL that is of the form: https://engr114.org/hub/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab . We only need part of this for the default_url . We'll keep everything after the https://engr114.org /hub/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab Modify jupyterhub_conf.py !!! Still does not work !!!. In jupyterhub_config.py modify the file to include: # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at a default nbgitpuller url. # Users pull down from the GitHub repo for the class automatically. c.Spawner.default_url = '/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab' ... Save the changes and restart JupyterHub. ## Restart JupyterHub and test it out ```text $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit Summary In this section we configured JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Defaut URL for nbGitpuller"},{"location":"nbgitpuller_defaut_url/#nbgitpuller-default-url","text":"In this section, we will discuss how one might configure the nbgitpuller URL from the previous section into the default URL for our JupyterHub site. This mean that any time a student goes to mydomain.org \u2192 mydomain.org/mycustomgitpullerurl The nbgitpuller plugin pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. When users go to a custom link such as: https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab users end up pulling all the files from the specified GitHub Repo into they JupyterHub folders. They see something like the following in their browser. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub.","title":"nbgitpuller default URL"},{"location":"nbgitpuller_defaut_url/#add-the-custom-link-to-jupyterhub_configpy","text":"We can add this the nbgitpuller custom link to the jupyterhub_config.py file. We did this before for when we made JupyterLab the default environment . Log into the server and shut down Jupyterhub. $ sudo systemctl stop jupyterhub cd to the /etc/jupyterhub/ directory and open up the jupyterhub_config.py file $ cd /etc/jupyterhub $ ls jupyterhub.sqlite jupyterhub_config.py jupyterhub_cookie_secret templates $ nano jupyterhub_config.py Inside the jupyterhub_config.py file, modify the line c.Spawner.default_url = '/lab' to instead point to the custom nbgitpuller URL. You can build a cusom nbgitpuller URL using this app: https://mybinder.org/v2/gh/jupyterhub/nbgitpuller/master?urlpath=apps/binder%2Flink_generator.ipynb This produces a URL that is of the form: https://engr114.org/hub/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab . We only need part of this for the default_url . We'll keep everything after the https://engr114.org /hub/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab","title":"Add the custom link to jupyterhub_config.py"},{"location":"nbgitpuller_defaut_url/#modify-jupyterhub_confpy-still-does-not-work","text":"In jupyterhub_config.py modify the file to include: # /etc/jupyterhub/jupyterhub_config.py ... # Start Users at a default nbgitpuller url. # Users pull down from the GitHub repo for the class automatically. c.Spawner.default_url = '/user-redirect/git-pull?repo=ProfessorKazarinoff%2FENGR114&branch=master&app=lab' ... Save the changes and restart JupyterHub. ## Restart JupyterHub and test it out ```text $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit","title":"Modify jupyterhub_conf.py !!! Still does not work !!!."},{"location":"nbgitpuller_defaut_url/#summary","text":"In this section we configured JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Summary"},{"location":"nbgitpuller_plugin/","text":"nbgitpuller Plugin In this section, we will install, enable and test the nbgitpuller plugin . nbgitpuller Plugin Introduction Install the nbgitpuller plugin Restart JupyterHub Build custom URL Go to the custom URL Summary Future Work Introduction The nbgitpuller plugin pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. The repo for the nbgitpuller plugin is here: https://github.com/jupyterhub/nbgitpuller#constructing-the-nbgitpuller-url The URL for the auto-generated URL contruction app in Binder is here: https://mybinder.org/v2/gh/jupyterhub/nbgitpuller/master?urlpath=apps/binder%2Flink_generator.ipynb Install the nbgitpuller plugin To install the nbgitpuller plugin for JupyterHub, first log into the server and stop JupyterHub. Then activate the (jupyterhubenv) virtual environment and pip install the plugin. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ pip install nbgitpuller After the plugin is installed, it needs to be enabled. (jupyterhubenv)$ jupyter serverextension enable --py nbgitpuller --sys-prefix (jupyterhubenv)$ conda deactivate $ Restart JupyterHub After the plugin is installed and enabled, restart JupyterHub and check the status. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit Build custom URL Go to the following link to the nbgitpull URL builder application running on Binder. https://hub.mybinder.org/user/jupyterhub-nbgitpuller-em8erjxr/apps/binder/link_generator.ipynb Go to the custom URL Point a browswer to the URL generated by the URL builder. The URL will be something like: https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab First we see the login screen: This brings us to the college login screen: Once logged in, we see the JupyterLab interface with all the folders and notebooks stored in the GitHub repo we specified. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub. Summary In this section we installed the nbgitpuller plugin for JupyterHub. Then we created a custom URL. When we browse to the custom URL, we enter our JupyterHub environment with all the files contained on GitHub placed in our user directory. This is a great plugin to have with JupyterHub. Now when we make changes to the Labs or Assignments in the GitHub Repo, those changes are reflected when students log into JupyterHub with the special URL. Future Work It would be nice if we could configure JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So that when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"nbGitpuller Plugin"},{"location":"nbgitpuller_plugin/#nbgitpuller-plugin","text":"In this section, we will install, enable and test the nbgitpuller plugin . nbgitpuller Plugin Introduction Install the nbgitpuller plugin Restart JupyterHub Build custom URL Go to the custom URL Summary Future Work","title":"nbgitpuller Plugin"},{"location":"nbgitpuller_plugin/#introduction","text":"The nbgitpuller plugin pulls down a GitHub repo into each student's JupyterHub environment when students start JupyterHub by clicking on a specific link. The repo for the nbgitpuller plugin is here: https://github.com/jupyterhub/nbgitpuller#constructing-the-nbgitpuller-url The URL for the auto-generated URL contruction app in Binder is here: https://mybinder.org/v2/gh/jupyterhub/nbgitpuller/master?urlpath=apps/binder%2Flink_generator.ipynb","title":"Introduction"},{"location":"nbgitpuller_plugin/#install-the-nbgitpuller-plugin","text":"To install the nbgitpuller plugin for JupyterHub, first log into the server and stop JupyterHub. Then activate the (jupyterhubenv) virtual environment and pip install the plugin. $ sudo systemctl stop jupyterhub $ conda activate jupyterhubenv (jupyterhubenv)$ pip install nbgitpuller After the plugin is installed, it needs to be enabled. (jupyterhubenv)$ jupyter serverextension enable --py nbgitpuller --sys-prefix (jupyterhubenv)$ conda deactivate $","title":"Install the nbgitpuller plugin"},{"location":"nbgitpuller_plugin/#restart-jupyterhub","text":"After the plugin is installed and enabled, restart JupyterHub and check the status. $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub [Ctrl]-[c] to exit","title":"Restart JupyterHub"},{"location":"nbgitpuller_plugin/#build-custom-url","text":"Go to the following link to the nbgitpull URL builder application running on Binder. https://hub.mybinder.org/user/jupyterhub-nbgitpuller-em8erjxr/apps/binder/link_generator.ipynb","title":"Build custom URL"},{"location":"nbgitpuller_plugin/#go-to-the-custom-url","text":"Point a browswer to the URL generated by the URL builder. The URL will be something like: https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab First we see the login screen: This brings us to the college login screen: Once logged in, we see the JupyterLab interface with all the folders and notebooks stored in the GitHub repo we specified. If we open one of the notebooks within JupyterHub, we see the same notebook that is stored on GitHub.","title":"Go to the custom URL"},{"location":"nbgitpuller_plugin/#summary","text":"In this section we installed the nbgitpuller plugin for JupyterHub. Then we created a custom URL. When we browse to the custom URL, we enter our JupyterHub environment with all the files contained on GitHub placed in our user directory. This is a great plugin to have with JupyterHub. Now when we make changes to the Labs or Assignments in the GitHub Repo, those changes are reflected when students log into JupyterHub with the special URL.","title":"Summary"},{"location":"nbgitpuller_plugin/#future-work","text":"It would be nice if we could configure JupyterHub to automatically go the the URL we setup with the nbgitpuller plugin. So that when students go to domain.org they get the same files as if they went to the custom plugin URL https://mydomain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Future Work"},{"location":"nginx_config/","text":"Nginx Configuration The next step is to modify the Nginx config file so that Nginx uses our SSL certificates and routes requests on to JupyterHub. Nginx Configuration Introduction Modify nginx.conf Restart Nginx Next Steps Introduction The Nginx configuration step was the hardest part for me when I set up my first JupyterHub server. The Nginx config file isn't Python code or a bash script. I went through many different variations until I finally got a config file that worked. The big initial problem was that I copied the sample Nginx config that's up on the JupyterHub docs. But the Nginx config posted on the JupyterHub docs is not a complete Nginx config, it contains just the server portion. I didn't know that the whole server portion needed to be enclosed in another frame. Modify nginx.conf To modify nginx.conf , cd into the /etc/nginx directory. The nginx.conf file should be there along with a couple other files and directories. $ cd /etc/nginx $ ls conf.d koi-utf nginx.conf sites-available ssl fastcgi.conf koi-win proxy_params sites-enabled uwsgi_params fastcgi_params mime.types scgi_params snippets win-utf $ sudo nano nginx.conf The nginx config that eventually worked for me is below. It can also be found here . Note the line which shows the path to the SSL certificates. This will change based on your domain name and where certbot saved the .pem files to. Remember to change the domain name in the line server_name mydomain.org; to your domain name. ## /etc/nginx/nginx.conf ## Based on: https://github.com/calpolydatascience/jupyterhub-deploy-data301/blob/master/roles/nginx/templates/nginx.conf.j2 user www-data; worker_processes 4; pid /run/nginx.pid; events { worker_connections 1024; # multi_accept on; } http { include /etc/nginx/mime.types; default_type application/octet-stream; #top-level http config for websocket headers # from https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/referen$ map $http_upgrade $connection_upgrade { default upgrade; '' close; } # All regular http requests on port 80 become SSL/HTTPS requests on port 32 server { listen 80; # !!! make sure to change this to your domain !!! server_name mydomain.org; # Tell all requests to port 80 to be 302 redirected to HTTPS return 302 https://$host$request_uri; } server { #listen 443 ssl default_server; listen 443; ssl on; # !!! make sure to change this to your domain !!! server_name mydomain.org; ## SSL Protocals # !!! make sure to change this to your domain !!! ssl_certificate /etc/letsencrypt/live/mydomain.org/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mydomain.org/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_dhparam /srv/jupyterhub/dhparam.pem; # Make site accessible from http://localhost/ server_name localhost; certs sent to the client in SERVER HELLO are concatenated in ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_stapling on; ssl_stapling_verify on; # modern configuration. tweak to your needs. ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; #proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /.well-known { allow all; } } } Save and exit with [Ctrl] + [x] and [Enter] Restart Nginx Now let's restart Nginx with our new configuration in place. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [ctrl-c] to exit If you have trouble with the restart, a useful command is: $ nginx -t When we browse to our domain name, we can see Nginx is running. Make sure to browse to https://mydomain.org and not https://www.mydomain.org . The cirtbot ssl cirtificut we got is only for https://mydomain.org and not the url that starts with www. . Next Steps The next step configure JupyterHub by creating and modifying a jupyterhub_config.py file.","title":"Nginx Configuration"},{"location":"nginx_config/#nginx-configuration","text":"The next step is to modify the Nginx config file so that Nginx uses our SSL certificates and routes requests on to JupyterHub. Nginx Configuration Introduction Modify nginx.conf Restart Nginx Next Steps","title":"Nginx Configuration"},{"location":"nginx_config/#introduction","text":"The Nginx configuration step was the hardest part for me when I set up my first JupyterHub server. The Nginx config file isn't Python code or a bash script. I went through many different variations until I finally got a config file that worked. The big initial problem was that I copied the sample Nginx config that's up on the JupyterHub docs. But the Nginx config posted on the JupyterHub docs is not a complete Nginx config, it contains just the server portion. I didn't know that the whole server portion needed to be enclosed in another frame.","title":"Introduction"},{"location":"nginx_config/#modify-nginxconf","text":"To modify nginx.conf , cd into the /etc/nginx directory. The nginx.conf file should be there along with a couple other files and directories. $ cd /etc/nginx $ ls conf.d koi-utf nginx.conf sites-available ssl fastcgi.conf koi-win proxy_params sites-enabled uwsgi_params fastcgi_params mime.types scgi_params snippets win-utf $ sudo nano nginx.conf The nginx config that eventually worked for me is below. It can also be found here . Note the line which shows the path to the SSL certificates. This will change based on your domain name and where certbot saved the .pem files to. Remember to change the domain name in the line server_name mydomain.org; to your domain name. ## /etc/nginx/nginx.conf ## Based on: https://github.com/calpolydatascience/jupyterhub-deploy-data301/blob/master/roles/nginx/templates/nginx.conf.j2 user www-data; worker_processes 4; pid /run/nginx.pid; events { worker_connections 1024; # multi_accept on; } http { include /etc/nginx/mime.types; default_type application/octet-stream; #top-level http config for websocket headers # from https://github.com/jupyterhub/jupyterhub/blob/master/docs/source/referen$ map $http_upgrade $connection_upgrade { default upgrade; '' close; } # All regular http requests on port 80 become SSL/HTTPS requests on port 32 server { listen 80; # !!! make sure to change this to your domain !!! server_name mydomain.org; # Tell all requests to port 80 to be 302 redirected to HTTPS return 302 https://$host$request_uri; } server { #listen 443 ssl default_server; listen 443; ssl on; # !!! make sure to change this to your domain !!! server_name mydomain.org; ## SSL Protocals # !!! make sure to change this to your domain !!! ssl_certificate /etc/letsencrypt/live/mydomain.org/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/mydomain.org/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_dhparam /srv/jupyterhub/dhparam.pem; # Make site accessible from http://localhost/ server_name localhost; certs sent to the client in SERVER HELLO are concatenated in ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_stapling on; ssl_stapling_verify on; # modern configuration. tweak to your needs. ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256'; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; location / { proxy_pass http://127.0.0.1:8000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-NginX-Proxy true; #proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } location ~ /.well-known { allow all; } } } Save and exit with [Ctrl] + [x] and [Enter]","title":"Modify nginx.conf"},{"location":"nginx_config/#restart-nginx","text":"Now let's restart Nginx with our new configuration in place. $ sudo systemctl stop nginx $ sudo systemctl start nginx $ sudo systemctl status nginx # [ctrl-c] to exit If you have trouble with the restart, a useful command is: $ nginx -t When we browse to our domain name, we can see Nginx is running. Make sure to browse to https://mydomain.org and not https://www.mydomain.org . The cirtbot ssl cirtificut we got is only for https://mydomain.org and not the url that starts with www. .","title":"Restart Nginx"},{"location":"nginx_config/#next-steps","text":"The next step configure JupyterHub by creating and modifying a jupyterhub_config.py file.","title":"Next Steps"},{"location":"nginx_install/","text":"Install Nginx In previous steps we accomplished the following: A domain name is set to route to our server We have our SSL cirt We created the three security files The next step is to install and configure Nginx. Nginx is an open-source web server that can handle many concurrent web connections at the same time. For the Nginx installation, I followed this tutorial from Digital Ocean. Log into the server, update the system, and install Nginx with the apt package manager. $ sudo apt-get update $ sudo apt-get upgrade $ sudo apt-get install nginx Digital Ocean installs a firewall application called ufw . Check out which apps the ufw firewall can work with: $ sudo ufw app list We see a list of available ufw configurations to work with Nginx: Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH We want to allow in both http and https requests. Once a http request comes in, we'll use Nginx to convert the http connection to a https connection. Select Nginx full . Note the C apitalization in the command: $ sudo ufw allow 'Nginx Full' We can check out which ports ufw is allowing through with: $ sudo ufw status Note the output shows ufw allows Nginx Full and requests over port 8000. We opened port 8000 earlier, so we could see how JupyterHub works without a domain name or SSL. Once we get Nginx running and hooked up to JupyterHub, we need to remember to close off port 8000 in ufw. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 ALLOW Anywhere 80 ALLOW Anywhere Nginx Full ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) ALLOW Anywhere (v6) 80 (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) Nginx will start running as soon at it is installed. We can see the status with: $ sudo systemctl status nginx In the output, we should see something like below. This mean Nginx is running. Key in [ctrl-c] to exit the status dashboard. Active: active (running) since Thu 2018-05-17 04:51:16 UTC; 15min ago Main PID: 17126 (nginx) CGroup: /system.slice/nginx.service \u251c\u2500\u2500 17126 nginx: master process /usr/sbin/nginx -g daemon on; master_pr \u2514\u2500\u2500 17127 nginx: worker process Now we can browse over to the domain (the domain we set up with Digital Ocean DNS dashboard and Google Domains) and see the Nginx start page. Next Steps Now that Nginx is installed, the next step is to configure Nginx to use our SSL certificate and run Nginx as a reverse proxy for our JupyterHub server.","title":"Install Nginx"},{"location":"nginx_install/#install-nginx","text":"In previous steps we accomplished the following: A domain name is set to route to our server We have our SSL cirt We created the three security files The next step is to install and configure Nginx. Nginx is an open-source web server that can handle many concurrent web connections at the same time. For the Nginx installation, I followed this tutorial from Digital Ocean. Log into the server, update the system, and install Nginx with the apt package manager. $ sudo apt-get update $ sudo apt-get upgrade $ sudo apt-get install nginx Digital Ocean installs a firewall application called ufw . Check out which apps the ufw firewall can work with: $ sudo ufw app list We see a list of available ufw configurations to work with Nginx: Available applications: Nginx Full Nginx HTTP Nginx HTTPS OpenSSH We want to allow in both http and https requests. Once a http request comes in, we'll use Nginx to convert the http connection to a https connection. Select Nginx full . Note the C apitalization in the command: $ sudo ufw allow 'Nginx Full' We can check out which ports ufw is allowing through with: $ sudo ufw status Note the output shows ufw allows Nginx Full and requests over port 8000. We opened port 8000 earlier, so we could see how JupyterHub works without a domain name or SSL. Once we get Nginx running and hooked up to JupyterHub, we need to remember to close off port 8000 in ufw. Status: active To Action From -- ------ ---- OpenSSH ALLOW Anywhere 8000 ALLOW Anywhere 80 ALLOW Anywhere Nginx Full ALLOW Anywhere OpenSSH (v6) ALLOW Anywhere (v6) 8000 (v6) ALLOW Anywhere (v6) 80 (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) Nginx will start running as soon at it is installed. We can see the status with: $ sudo systemctl status nginx In the output, we should see something like below. This mean Nginx is running. Key in [ctrl-c] to exit the status dashboard. Active: active (running) since Thu 2018-05-17 04:51:16 UTC; 15min ago Main PID: 17126 (nginx) CGroup: /system.slice/nginx.service \u251c\u2500\u2500 17126 nginx: master process /usr/sbin/nginx -g daemon on; master_pr \u2514\u2500\u2500 17127 nginx: worker process Now we can browse over to the domain (the domain we set up with Digital Ocean DNS dashboard and Google Domains) and see the Nginx start page.","title":"Install Nginx"},{"location":"nginx_install/#next-steps","text":"Now that Nginx is installed, the next step is to configure Nginx to use our SSL certificate and run Nginx as a reverse proxy for our JupyterHub server.","title":"Next Steps"},{"location":"periodic_maintenance/","text":"Periodic Maintenance After running JupyterHub for two quarters, there are a couple lessons I've learned about maintenance. Increase server size before class starts Right at the beginning of class, when everyone logs in, the server can get overloaded. So during only class times when 24 students plus 1 instructor will all be logged into the JupyterHub server at the same time, boost the server size to a $40/month or maybe even up to an $80/month server. You can update the server size at the Digital Ocean Dashboard, but the server has to be shut down first at the command line. $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Log onto Digital Ocean and select the project and server running JupyterHub. Make sure the \"power slider\" is set to [off]. Then select the $80/month server and click [Upgrade Server]. Now many students should be able to log in and run JupyterHub at the same time. After the server restarts, Nginx and JupyterHub have to be restared as well. Key in the following commands after the server size is increased and the \"power slider\" is set to [on]. $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Important Remember to drop the server size back down after class ends or the Digital Ocean bill will get quite large! You don't want to rack up a huge bill with Digital Ocean. During the rest of the regular week (not during class time), the server can be smaller and cheaper becuase only a few users at a time will be logged in at the same time. Restart server once a week The Hub seems to get sluggish when it has been running for a long time continously. Shutting the down JupyterHub, Nginx, then restarting the server once each week seems like a good idea. To restart the server, first log into JupyterHub and shut down all the student servers. Then from the command line, run: $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Then go to the Digital Ocean dashboard and restart the server. After the server restarts, restart nginx then JupyterHub. $ sudo systemctl start nginx $ sudo systemctl status nginx $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub Extras There are a couple extra docs pages. Browse through these if you want to use the JupyterLab interface, include a GitHub in the JupyterLab interface or try and make the regular domain name go to the nbgitpuller domain name.","title":"Periodic Maintenance"},{"location":"periodic_maintenance/#periodic-maintenance","text":"After running JupyterHub for two quarters, there are a couple lessons I've learned about maintenance.","title":"Periodic Maintenance"},{"location":"periodic_maintenance/#increase-server-size-before-class-starts","text":"Right at the beginning of class, when everyone logs in, the server can get overloaded. So during only class times when 24 students plus 1 instructor will all be logged into the JupyterHub server at the same time, boost the server size to a $40/month or maybe even up to an $80/month server. You can update the server size at the Digital Ocean Dashboard, but the server has to be shut down first at the command line. $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Log onto Digital Ocean and select the project and server running JupyterHub. Make sure the \"power slider\" is set to [off]. Then select the $80/month server and click [Upgrade Server]. Now many students should be able to log in and run JupyterHub at the same time. After the server restarts, Nginx and JupyterHub have to be restared as well. Key in the following commands after the server size is increased and the \"power slider\" is set to [on]. $ sudo systemctl start nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit Important Remember to drop the server size back down after class ends or the Digital Ocean bill will get quite large! You don't want to rack up a huge bill with Digital Ocean. During the rest of the regular week (not during class time), the server can be smaller and cheaper becuase only a few users at a time will be logged in at the same time.","title":"Increase server size before class starts"},{"location":"periodic_maintenance/#restart-server-once-a-week","text":"The Hub seems to get sluggish when it has been running for a long time continously. Shutting the down JupyterHub, Nginx, then restarting the server once each week seems like a good idea. To restart the server, first log into JupyterHub and shut down all the student servers. Then from the command line, run: $ sudo systemctl stop jupyterhub $ sudo systemctl status jupyterhub # [Ctrl]+[c] to exit $ sudo systemctl stop nginx $ sudo systemctl status nginx # [Ctrl]+[c] to exit $ sudo shutdown -h now Then go to the Digital Ocean dashboard and restart the server. After the server restarts, restart nginx then JupyterHub. $ sudo systemctl start nginx $ sudo systemctl status nginx $ sudo systemctl start jupyterhub $ sudo systemctl status jupyterhub","title":"Restart server once a week"},{"location":"periodic_maintenance/#extras","text":"There are a couple extra docs pages. Browse through these if you want to use the JupyterLab interface, include a GitHub in the JupyterLab interface or try and make the regular domain name go to the nbgitpuller domain name.","title":"Extras"},{"location":"renew_ssl_cert/","text":"Renew SSL Certificate After about two months, the SSL certificate we obtained with certbot in a previous step needs to be updated. The SSL cert will need to be renewed with certbot so that we can continue running HTTPS on our JupyterHub server. Renew SSL Certificate Why Does the SSL Cirt Expire? Updating the SSL cirt Summary Why Does the SSL Cirt Expire? When we used certbot to obtain an SSL certificut, the certificate we aquired was only applicable for 90 days. I recieved an email reminding me that the SSL cert needed to be updated: Hello, Your certificate (or certificates) for the names listed below will expire in 10 days (on 12 Nov 19 04:23 +0000). Please make sure to renew your certificate before then, or visitors to your website will encounter errors. We recommend renewing certificates automatically when they have a third of their total lifetime left. For Let's Encrypt's current 90-day certificates, that means renewing 30 days before expiration. See https://letsencrypt.org/docs/integration-guide/ for details. Updating the SSL cirt To update the SSL cert, we need to run certbot-auto renew in the correct directory. Previously, we installed certbot into /home/peter/cirtbot on our JupyterHub server. To renew the certificate, log into the server and navigate to the directory where certbot is installed. $ cd cirtbot $ pwd /home/peter/cirtbot $ ./certbot-auto renew ... Congratulations, all renewals succeeded... If this command doesn't work, there may be a problem if port 80 is closed by the ufw firewall. Open port 80 in ufw with the command below: $ sudo ufw allow 80 If the ./certbot-auto renew command still doesn't work, try shutting down JupyterHub and Nginx. Log into JupyterHub as an admin user and shut down any running servers first. $ sudo systemclt stop jupyterhub $ sudo systemctl stop nginx $ pwd /home/peter/cirtbot $ ./certbot-auto renew If JupyterHub and Nginx are both shut down, they both need to restarted after the SSL cert is renewed. $ sudo systemctl start nginx $ sudo systemctl start jupyterhub Also, if port 80 was opened, close port 80 after the cert is renewed. The only ports/apps that need to be allowed by the ufw firewall are Nginx and OpenSSH. All other ports like 80 and 8000 can be closed in ufw. Important Only open ports and apps in the ufw firewall that are needed to run JupyterHub and Nginx. Close all other ports in ufw. $ sudo ufw deny 80 Then log back into JupyterHub as a user. Make sure everything still works as before. Summary After completing these steps, we have a new SSL cert that is valid for 90 days. The SSL can be renewed using the same steps outlined above when it needs to be renewed again.","title":"Renew SSL Certificate"},{"location":"renew_ssl_cert/#renew-ssl-certificate","text":"After about two months, the SSL certificate we obtained with certbot in a previous step needs to be updated. The SSL cert will need to be renewed with certbot so that we can continue running HTTPS on our JupyterHub server. Renew SSL Certificate Why Does the SSL Cirt Expire? Updating the SSL cirt Summary","title":"Renew SSL Certificate"},{"location":"renew_ssl_cert/#why-does-the-ssl-cirt-expire","text":"When we used certbot to obtain an SSL certificut, the certificate we aquired was only applicable for 90 days. I recieved an email reminding me that the SSL cert needed to be updated: Hello, Your certificate (or certificates) for the names listed below will expire in 10 days (on 12 Nov 19 04:23 +0000). Please make sure to renew your certificate before then, or visitors to your website will encounter errors. We recommend renewing certificates automatically when they have a third of their total lifetime left. For Let's Encrypt's current 90-day certificates, that means renewing 30 days before expiration. See https://letsencrypt.org/docs/integration-guide/ for details.","title":"Why Does the SSL Cirt Expire?"},{"location":"renew_ssl_cert/#updating-the-ssl-cirt","text":"To update the SSL cert, we need to run certbot-auto renew in the correct directory. Previously, we installed certbot into /home/peter/cirtbot on our JupyterHub server. To renew the certificate, log into the server and navigate to the directory where certbot is installed. $ cd cirtbot $ pwd /home/peter/cirtbot $ ./certbot-auto renew ... Congratulations, all renewals succeeded... If this command doesn't work, there may be a problem if port 80 is closed by the ufw firewall. Open port 80 in ufw with the command below: $ sudo ufw allow 80 If the ./certbot-auto renew command still doesn't work, try shutting down JupyterHub and Nginx. Log into JupyterHub as an admin user and shut down any running servers first. $ sudo systemclt stop jupyterhub $ sudo systemctl stop nginx $ pwd /home/peter/cirtbot $ ./certbot-auto renew If JupyterHub and Nginx are both shut down, they both need to restarted after the SSL cert is renewed. $ sudo systemctl start nginx $ sudo systemctl start jupyterhub Also, if port 80 was opened, close port 80 after the cert is renewed. The only ports/apps that need to be allowed by the ufw firewall are Nginx and OpenSSH. All other ports like 80 and 8000 can be closed in ufw. Important Only open ports and apps in the ufw firewall that are needed to run JupyterHub and Nginx. Close all other ports in ufw. $ sudo ufw deny 80 Then log back into JupyterHub as a user. Make sure everything still works as before.","title":"Updating the SSL cirt"},{"location":"renew_ssl_cert/#summary","text":"After completing these steps, we have a new SSL cert that is valid for 90 days. The SSL can be renewed using the same steps outlined above when it needs to be renewed again.","title":"Summary"},{"location":"setup/","text":"Set Up Before we launch into the server setup, let's quickly review where certain files are going to go: File Locations and Directory Structure According to the JuptyerHub docs : The folks at JupyterHub recommend that we put all of the files used by JupyterHub into standard UNIX filesystem locations on our server: /srv/jupyterhub for all security and runtime files /etc/jupyterhub for all configuration files /var/log for log files Development tools Before creating the server, a set of private/public SSH keys are needed. SSH keys can be created with PuTTY Gen . PuTTY Gen is installed with a typical PuTTY installation. See this post for details. A SSH terminal program is needed to communicate with the server. On Windows 10, I use PuTTY . See this post for details. On MacOS and Linux, SSH from the command line works as well. It is helpful to have an SFTP client to move large files back and forth between a local computer and the server. On Windows 10, I use FileZilla . Locally, I use the Anaconda distribution of Python and the Anaconda Prompt to create virtual environments and run Python code. This JupyterHub deployment runs on a Digital Ocean virtual private server. Local development and testing was completed on a Windows 10 laptop and desktop. Next Steps The next step is to create a public-private SSH key pair with PuTTYgen. We'll use this public-private SSH key to log into the server with PuTTY.","title":"Set Up and Tools"},{"location":"setup/#set-up","text":"Before we launch into the server setup, let's quickly review where certain files are going to go:","title":"Set Up"},{"location":"setup/#file-locations-and-directory-structure","text":"According to the JuptyerHub docs : The folks at JupyterHub recommend that we put all of the files used by JupyterHub into standard UNIX filesystem locations on our server: /srv/jupyterhub for all security and runtime files /etc/jupyterhub for all configuration files /var/log for log files","title":"File Locations and Directory Structure"},{"location":"setup/#development-tools","text":"Before creating the server, a set of private/public SSH keys are needed. SSH keys can be created with PuTTY Gen . PuTTY Gen is installed with a typical PuTTY installation. See this post for details. A SSH terminal program is needed to communicate with the server. On Windows 10, I use PuTTY . See this post for details. On MacOS and Linux, SSH from the command line works as well. It is helpful to have an SFTP client to move large files back and forth between a local computer and the server. On Windows 10, I use FileZilla . Locally, I use the Anaconda distribution of Python and the Anaconda Prompt to create virtual environments and run Python code. This JupyterHub deployment runs on a Digital Ocean virtual private server. Local development and testing was completed on a Windows 10 laptop and desktop.","title":"Development tools"},{"location":"setup/#next-steps","text":"The next step is to create a public-private SSH key pair with PuTTYgen. We'll use this public-private SSH key to log into the server with PuTTY.","title":"Next Steps"},{"location":"ssh_keys/","text":"Create SSH keys SSH keys allow us to log into the cloud server which will run JupyterHub. SSH keys come in pairs, a private key and a public key. The public key will be stored on the JupyterHub cloud server and the private key will stay secure on our local machine. Create SSH keys Why SSH keys, PuTTYgen and why do this first? Download PuTTY Start PuTTYgen and create SSH key Save SSH public and private keys to Documents folder Copy the public key to clipboard Summary Next Steps Why SSH keys, PuTTYgen and why do this first? The first time I set up a JupyterHub server, one of the initial setup steps was to add SSH keys to the server (so the server has the SSH key when it initialized). I tried to create and save the SSH keys to the Digital Ocean (the cloud server provider) dashboard so the SSH keys would be on the server when the server first started. But I goofed up somehow and the server started without any SSH keys. Note It was a BIG PAIN to add SSH keys after the server started for the first time. I ended up copying the public SSH key into pastebin.com, logging onto the server with the Digital Ocean console and used wget to bring a textfile of the SSH key from pastebin.com onto the server and then used mv to copy the key name into the right location. I'm pretty sure pasting a public SSH key into pastebin.com is not the best way to initially set up a cloud server. So to make sure that doesn't happen again, we are going to generate the SSH keys first, and set up the server second. SSH keys are needed to use PuTTY (regular PuTTY not PuTTYgen) to log into the server. Since I'm working on Windows 10, using PuTTYgen (a program that comes with PuTTY which generates SSH keys) seems like the easiest solution. Download PuTTY I already have PuTTY installed on my Windows 10 machines at home and at work. The download link is below: Download PuTTY PuTTY seems to want to install lots of extra stuff when you run the installer. I didn't install any of the \"offers\" that popped up during installation. Start PuTTYgen and create SSH key I went through this tutorial to learn how to set up SSH keys on Windows 10 for Digital Ocean when I created the first SSH key. Using the Windows start menu, open PuTTYgen (not regular PuTTY): Use the following parameters Type of key to generate: RSA Number of bits in generated key: 2048 Then click [generate] This brings up a dialog to move the mouse around the empty area to generate some randomness. This is my favorite part! Just move the mouse around the dialog box until the progress bar ends. Fun. When the next screen pops up, right-click and copy the contents of the Public Key. We'll need the public key contents available to paste into the server's SSH authorized_keys file. Include the rsa line in the text copied to the clipboard. Save SSH public and private keys to Documents folder In the [Actions] section click [Save public key] and click [Save private key] Make sure to save both the public and the private keys. Save these keys to an accessible folder. The first time I generated SSH keys, I saved the keys in the default location and couldn't access them later. The second time I created SSH keys, I created a folder in the Documents folder called ssh-keys and saved the public and private keys in Documents\\ssh-keys . I saved the public key with the name: public_key_jupyter_hub.txt . The Digital Ocean documentation recommends a .txt file extension for the public key (so you can open it and copy the contents). The private key should have a .ppk file extension. Copy the public key to clipboard Before closing PuTTYgen, make sure to copy the contents of the Public Key to the clipboard. We'll need the public key contents when we create the server. Copy all of the contents of the public SSH key including the rsa line. Summary After completing these steps, we have a public and private SSH key pair saved in Documents\\ssh-keys . We also have the contents of the public SSH key saved to the clipboard. Next Steps Next, we'll create a new server on Digital Ocean (called a droplet ). Then we'll use the SSH keys we just created to log into the server and create a non-root sudo user.","title":"SSH Keys"},{"location":"ssh_keys/#create-ssh-keys","text":"SSH keys allow us to log into the cloud server which will run JupyterHub. SSH keys come in pairs, a private key and a public key. The public key will be stored on the JupyterHub cloud server and the private key will stay secure on our local machine. Create SSH keys Why SSH keys, PuTTYgen and why do this first? Download PuTTY Start PuTTYgen and create SSH key Save SSH public and private keys to Documents folder Copy the public key to clipboard Summary Next Steps","title":"Create SSH keys"},{"location":"ssh_keys/#why-ssh-keys-puttygen-and-why-do-this-first","text":"The first time I set up a JupyterHub server, one of the initial setup steps was to add SSH keys to the server (so the server has the SSH key when it initialized). I tried to create and save the SSH keys to the Digital Ocean (the cloud server provider) dashboard so the SSH keys would be on the server when the server first started. But I goofed up somehow and the server started without any SSH keys. Note It was a BIG PAIN to add SSH keys after the server started for the first time. I ended up copying the public SSH key into pastebin.com, logging onto the server with the Digital Ocean console and used wget to bring a textfile of the SSH key from pastebin.com onto the server and then used mv to copy the key name into the right location. I'm pretty sure pasting a public SSH key into pastebin.com is not the best way to initially set up a cloud server. So to make sure that doesn't happen again, we are going to generate the SSH keys first, and set up the server second. SSH keys are needed to use PuTTY (regular PuTTY not PuTTYgen) to log into the server. Since I'm working on Windows 10, using PuTTYgen (a program that comes with PuTTY which generates SSH keys) seems like the easiest solution.","title":"Why SSH keys, PuTTYgen and why do this first?"},{"location":"ssh_keys/#download-putty","text":"I already have PuTTY installed on my Windows 10 machines at home and at work. The download link is below: Download PuTTY PuTTY seems to want to install lots of extra stuff when you run the installer. I didn't install any of the \"offers\" that popped up during installation.","title":"Download PuTTY"},{"location":"ssh_keys/#start-puttygen-and-create-ssh-key","text":"I went through this tutorial to learn how to set up SSH keys on Windows 10 for Digital Ocean when I created the first SSH key. Using the Windows start menu, open PuTTYgen (not regular PuTTY): Use the following parameters Type of key to generate: RSA Number of bits in generated key: 2048 Then click [generate] This brings up a dialog to move the mouse around the empty area to generate some randomness. This is my favorite part! Just move the mouse around the dialog box until the progress bar ends. Fun. When the next screen pops up, right-click and copy the contents of the Public Key. We'll need the public key contents available to paste into the server's SSH authorized_keys file. Include the rsa line in the text copied to the clipboard.","title":"Start PuTTYgen and create SSH key"},{"location":"ssh_keys/#save-ssh-public-and-private-keys-to-documents-folder","text":"In the [Actions] section click [Save public key] and click [Save private key] Make sure to save both the public and the private keys. Save these keys to an accessible folder. The first time I generated SSH keys, I saved the keys in the default location and couldn't access them later. The second time I created SSH keys, I created a folder in the Documents folder called ssh-keys and saved the public and private keys in Documents\\ssh-keys . I saved the public key with the name: public_key_jupyter_hub.txt . The Digital Ocean documentation recommends a .txt file extension for the public key (so you can open it and copy the contents). The private key should have a .ppk file extension.","title":"Save SSH public and private keys to Documents folder"},{"location":"ssh_keys/#copy-the-public-key-to-clipboard","text":"Before closing PuTTYgen, make sure to copy the contents of the Public Key to the clipboard. We'll need the public key contents when we create the server. Copy all of the contents of the public SSH key including the rsa line.","title":"Copy the public key to clipboard"},{"location":"ssh_keys/#summary","text":"After completing these steps, we have a public and private SSH key pair saved in Documents\\ssh-keys . We also have the contents of the public SSH key saved to the clipboard.","title":"Summary"},{"location":"ssh_keys/#next-steps","text":"Next, we'll create a new server on Digital Ocean (called a droplet ). Then we'll use the SSH keys we just created to log into the server and create a non-root sudo user.","title":"Next Steps"},{"location":"ssl/","text":"Obtain an SSL Certificate In the last step, we hooked up a qualified domain name to our JupyterHub server. So now we'll be able to obtain an SSL certificate that goes with the specific domain. I followed this presentation to install certbot , a program used to generate SSL certificates. Obtain an SSL Certificate Install and run certbot File Locations Next Steps Install and run certbot We'll use certbot to obtain a standalone SSL certificate for our JupyterHub server. But wait - we need to make sure that port 80 is open on the ufw firewall. If port 80 is closed, cirtbot won't be able to verify that our domain name is correctly configured. So before running cirtbot, make sure to open port 80. $ sudo ufw allow 80 $ sudo ufw status Now use the commands below to install certbot, modify permissions, and run certbot to obtain an SSL certificate. Make sure to replace mydomain.org with your domain name. $ cd ~ $ mkdir certbot $ cd certbot $ wget https://dl.eff.org/certbot-auto $ chmod a+x certbot-auto $ ./certbot-auto certonly --standalone -d mydomain.org If certbot worked, and we get an SSL certificate- the output looks something like below: IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/mydomain.org/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/mydomain.org/privkey.pem Your cert will expire on 2018-08-15. File Locations Note the location of the fullchain.pem and privkey.pem files. In a future step, we'll add these file paths into our Nginx configuration . We also need to allow Nginx to access these files. I had trouble getting Nginx to run and this presentation showed a way to give Nginx access to the SSL key files. There is probably a more \"Linuxy\" way of giving Nginx access to the cert files, but I messed around with the permission settings for a while, and using the commands below worked. $ cd /etc/letsencrypt $ ls accounts archive csr keys live renewal renewal-hooks $ sudo chmod 777 -R archive/ $ sudo chmod 777 -R live/ $ ls -la Next Steps The next step is to create a cookie secret, proxy auth token, and dhparem.pem file.","title":"SSL Certificates"},{"location":"ssl/#obtain-an-ssl-certificate","text":"In the last step, we hooked up a qualified domain name to our JupyterHub server. So now we'll be able to obtain an SSL certificate that goes with the specific domain. I followed this presentation to install certbot , a program used to generate SSL certificates. Obtain an SSL Certificate Install and run certbot File Locations Next Steps","title":"Obtain an SSL Certificate"},{"location":"ssl/#install-and-run-certbot","text":"We'll use certbot to obtain a standalone SSL certificate for our JupyterHub server. But wait - we need to make sure that port 80 is open on the ufw firewall. If port 80 is closed, cirtbot won't be able to verify that our domain name is correctly configured. So before running cirtbot, make sure to open port 80. $ sudo ufw allow 80 $ sudo ufw status Now use the commands below to install certbot, modify permissions, and run certbot to obtain an SSL certificate. Make sure to replace mydomain.org with your domain name. $ cd ~ $ mkdir certbot $ cd certbot $ wget https://dl.eff.org/certbot-auto $ chmod a+x certbot-auto $ ./certbot-auto certonly --standalone -d mydomain.org If certbot worked, and we get an SSL certificate- the output looks something like below: IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/mydomain.org/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/mydomain.org/privkey.pem Your cert will expire on 2018-08-15.","title":"Install and run certbot"},{"location":"ssl/#file-locations","text":"Note the location of the fullchain.pem and privkey.pem files. In a future step, we'll add these file paths into our Nginx configuration . We also need to allow Nginx to access these files. I had trouble getting Nginx to run and this presentation showed a way to give Nginx access to the SSL key files. There is probably a more \"Linuxy\" way of giving Nginx access to the cert files, but I messed around with the permission settings for a while, and using the commands below worked. $ cd /etc/letsencrypt $ ls accounts archive csr keys live renewal renewal-hooks $ sudo chmod 777 -R archive/ $ sudo chmod 777 -R live/ $ ls -la","title":"File Locations"},{"location":"ssl/#next-steps","text":"The next step is to create a cookie secret, proxy auth token, and dhparem.pem file.","title":"Next Steps"},{"location":"systemd/","text":"Run JupyterHub as a system service Running JupyerHub as a system service allows JupyterHub to run continously even if we aren't logged into the server. It also keeps JupyterHub running while when we log into the server and make any changes. Run JupyterHub as a system service Create a jupyterhub.service file Reload the systemd daemon and start the system service Test local OAuth Next Steps Create a jupyterhub.service file To run JupyterHub as a system service (according to this wiki ), we need to create a service file in the /etc/systemd/system directory. cd into the directory and have a look around. We see a couple files that end in .service $ cd /etc/systemd/system $ ls cloud-init.target.wants network-online.target.wants dbus-org.freedesktop.thermald.service paths.target.wants default.target.wants sockets.target.wants final.target.wants sshd.service getty.target.wants sysinit.target.wants graphical.target.wants syslog.service iscsi.service timers.target.wants multi-user.target.wants Create a new .service file called jupyterhub.service $ sudo nano jupyterhub.service In the jupyterhub.service file, add the following. Note that as part of the PATH environment variable /opt/miniconda3/envs/jupyterhubenv/bin/ is included. This is the path to our virtual environment. As part of the ExecStart= section, include a flag for our JupyterHub config file located at /etc/jupyterhub/jupyterhub_config.py . [Unit] Description=JupyterHub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/miniconda3/envs/jupyterhubenv/bin/\" ExecStart=/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target Save and exit the nano text editor with [Ctrl-x] + [Enter]. Reload the systemd daemon and start the system service Now we need to reload the system daemon and run JupyterHub as a system service using the command: sudo systemctl <start|stop|status> jupyterhub $ sudo systemctl daemon-reload $ sudo systemctl start jupyterhub We can see if JupyterHub is running with: $ sudo systemctl status jupyterhub Loaded: loaded (/etc/systemd/system/jupyterhub.service; Active: active (running) Test local OAuth Now we can go to the server and log in as our non-root user peter . A couple times I thought that JupyterHub was running after using systemctl start jupyterhub , but the JupyterHub wasn't working when I went to the server's web address. It turned out that JupyterHub wasn't running when I keyed in systemctl status jupyterhub . Most times looking for an error and tracking down the the error worked, but one time it seemed to be a problem with the http-configurable-proxy. The following command shuts down the proxy if you get stuck like I did (insert the number corresponding to the configurable-http-proxy process after the kill command): $ ps aux | grep configurable-http-proxy $ kill #### Next Steps The next step is to have JupyterHub accept Google usernames and passwords. This allows students with college email accounts to log into JupyterHub and means we don't have to deal with creating new users and sending students usernames and passwords.","title":"System Service"},{"location":"systemd/#run-jupyterhub-as-a-system-service","text":"Running JupyerHub as a system service allows JupyterHub to run continously even if we aren't logged into the server. It also keeps JupyterHub running while when we log into the server and make any changes. Run JupyterHub as a system service Create a jupyterhub.service file Reload the systemd daemon and start the system service Test local OAuth Next Steps","title":"Run JupyterHub as a system service"},{"location":"systemd/#create-a-jupyterhubservice-file","text":"To run JupyterHub as a system service (according to this wiki ), we need to create a service file in the /etc/systemd/system directory. cd into the directory and have a look around. We see a couple files that end in .service $ cd /etc/systemd/system $ ls cloud-init.target.wants network-online.target.wants dbus-org.freedesktop.thermald.service paths.target.wants default.target.wants sockets.target.wants final.target.wants sshd.service getty.target.wants sysinit.target.wants graphical.target.wants syslog.service iscsi.service timers.target.wants multi-user.target.wants Create a new .service file called jupyterhub.service $ sudo nano jupyterhub.service In the jupyterhub.service file, add the following. Note that as part of the PATH environment variable /opt/miniconda3/envs/jupyterhubenv/bin/ is included. This is the path to our virtual environment. As part of the ExecStart= section, include a flag for our JupyterHub config file located at /etc/jupyterhub/jupyterhub_config.py . [Unit] Description=JupyterHub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/miniconda3/envs/jupyterhubenv/bin/\" ExecStart=/opt/miniconda3/envs/jupyterhubenv/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target Save and exit the nano text editor with [Ctrl-x] + [Enter].","title":"Create a jupyterhub.service file"},{"location":"systemd/#reload-the-systemd-daemon-and-start-the-system-service","text":"Now we need to reload the system daemon and run JupyterHub as a system service using the command: sudo systemctl <start|stop|status> jupyterhub $ sudo systemctl daemon-reload $ sudo systemctl start jupyterhub We can see if JupyterHub is running with: $ sudo systemctl status jupyterhub Loaded: loaded (/etc/systemd/system/jupyterhub.service; Active: active (running)","title":"Reload the systemd daemon and start the system service"},{"location":"systemd/#test-local-oauth","text":"Now we can go to the server and log in as our non-root user peter . A couple times I thought that JupyterHub was running after using systemctl start jupyterhub , but the JupyterHub wasn't working when I went to the server's web address. It turned out that JupyterHub wasn't running when I keyed in systemctl status jupyterhub . Most times looking for an error and tracking down the the error worked, but one time it seemed to be a problem with the http-configurable-proxy. The following command shuts down the proxy if you get stuck like I did (insert the number corresponding to the configurable-http-proxy process after the kill command): $ ps aux | grep configurable-http-proxy $ kill ####","title":"Test local OAuth"},{"location":"systemd/#next-steps","text":"The next step is to have JupyterHub accept Google usernames and passwords. This allows students with college email accounts to log into JupyterHub and means we don't have to deal with creating new users and sending students usernames and passwords.","title":"Next Steps"},{"location":"useful_commands/","text":"Usefull Commands Below are some useful commands for setting up and running JupyterHub kill configurable-http-proxy ps aux | grep configurable-http-proxy kill #### nginx sudo service nginx stop sudo service nginx start sudo service nginx restart nginx -t Shutdown and restart server sudo shutdown -r now Start JupyterHub with sudo (need to do this to allow other users to logon) sudo /home/peter/anaconda3/bin/jupyterhub Start jupyterhub as service, will run continuously sudo systemctl start jupyterhub sudo systemctl <start|stop|status> jupyterhub Add environmental variables: $ export OAUTH_CLIENT_SECRET=xxxxxxxxxxx Gitpuller extension URLs https://domain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab Change the systemctl start jupyterhub configurations If changes are made to /etc/systemd/system/jupyterhub.service , need to reload: sudo systemctl daemon-reload sudo systemctl start jupyterhub Similar to the above but with a couple changes. Assuming you're using /opt/anaconda3/jupyterhub for your configs, save this as /etc/systemd/system/jupyterhub.service [Unit] Description=Jupyterhub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/anaconda3/bin\" ExecStart=/opt/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target","title":"Useful Commands"},{"location":"useful_commands/#usefull-commands","text":"Below are some useful commands for setting up and running JupyterHub","title":"Usefull Commands"},{"location":"useful_commands/#kill-configurable-http-proxy","text":"ps aux | grep configurable-http-proxy kill ####","title":"kill configurable-http-proxy"},{"location":"useful_commands/#nginx","text":"sudo service nginx stop sudo service nginx start sudo service nginx restart nginx -t","title":"nginx"},{"location":"useful_commands/#shutdown-and-restart-server","text":"sudo shutdown -r now","title":"Shutdown and restart server"},{"location":"useful_commands/#start-jupyterhub-with-sudo-need-to-do-this-to-allow-other-users-to-logon","text":"sudo /home/peter/anaconda3/bin/jupyterhub","title":"Start JupyterHub with sudo (need to do this to allow other users to logon)"},{"location":"useful_commands/#start-jupyterhub-as-service-will-run-continuously","text":"sudo systemctl start jupyterhub sudo systemctl <start|stop|status> jupyterhub","title":"Start jupyterhub as service, will run continuously"},{"location":"useful_commands/#add-environmental-variables","text":"$ export OAUTH_CLIENT_SECRET=xxxxxxxxxxx","title":"Add environmental variables:"},{"location":"useful_commands/#gitpuller-extension-urls","text":"https://domain.org/hub/user-redirect/git-pull?repo=GitHubUserName%2FRepoName&branch=master&app=lab","title":"Gitpuller extension URLs"},{"location":"useful_commands/#change-the-systemctl-start-jupyterhub-configurations","text":"If changes are made to /etc/systemd/system/jupyterhub.service , need to reload: sudo systemctl daemon-reload sudo systemctl start jupyterhub Similar to the above but with a couple changes. Assuming you're using /opt/anaconda3/jupyterhub for your configs, save this as /etc/systemd/system/jupyterhub.service [Unit] Description=Jupyterhub After=syslog.target network.target [Service] User=root Environment=\"PATH=/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/anaconda3/bin\" ExecStart=/opt/anaconda3/bin/jupyterhub -f /etc/jupyterhub/jupyterhub_config.py [Install] WantedBy=multi-user.target","title":"Change the systemctl start jupyterhub configurations"}]}